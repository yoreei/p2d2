{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true,"id":"ur2KW1sdnCxW","colab_type":"code","outputId":"f584d998-ff68-4aea-8b52-f2159fc35774","colab":{}},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"YdiPFmywqP-j","colab_type":"code","colab":{}},"cell_type":"code","source":"#import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)","execution_count":0,"outputs":[]},{"metadata":{"id":"Lt0UTr9JnCxc","colab_type":"text"},"cell_type":"markdown","source":"## Purpose\nFor this project, I will be using Twitter hashtags, sentiment scores, and music streaming session data from Spotify to predict the next song to be played.\n\n## OBTAIN & SCRUB: Prepare the Datasets\n* Load 3 datasets: **sentiment_values.csv, user_track_hashtag_timestamp.csv and context_content_features.csv**\n* Data type conversions (e.g. numeric data mistakenly encoded as objects)\n* Detect and deal with missing values\n* Remove unnecessary columns"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"id":"eeqIIUuhnCxd","colab_type":"code","outputId":"3eb50f87-f84a-4400-a6c0-d1e6843a504b","colab":{}},"cell_type":"code","source":"#Load the sentiment_values.csv - The smallest dataset\ndf = pd.read_csv('../input/nowplayingrs/sentiment_values.csv')\n\n#Look at size of the dataset\ndf.shape","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"PbHag8wbnCxf","colab_type":"code","outputId":"e63a2cc8-7752-4a55-a2ba-43106bd6a13a","colab":{}},"cell_type":"code","source":"#Look at the columns and initial rows of the dataset\ndf.head()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"mM54sFp_nCxh","colab_type":"code","outputId":"4987df55-1c11-4cdc-d32b-8368affcd6af","colab":{}},"cell_type":"code","source":"#Rename hashtag column\ndf.rename(columns = {'hashtag':'ss_score'}, inplace = True)\n\n#Reset index\ndf.reset_index(inplace=True)\n\n#Rename columns\ndf.rename(columns = {'level_0':'hashtag','level_1':'vader_score','level_2':'afinn_score','level_3':'ol_score'}, inplace = True)\n\n#Show dataset to confirm changes\ndf.head()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"J1eq2qfhnCxi","colab_type":"code","colab":{}},"cell_type":"code","source":"#Set columns\ndf.columns=['hashtag','vader_score','afinn_score','ol_score','ss_score','vader_min','vader_max','vader_sum','vader_avg','afinn_min',\n            'afinn_max','afinn_sum','afinn_avg','ol_min','ol_max','ol_sum','ol_avg','ss_min','ss_max','ss_sum','ss_avg']","execution_count":0,"outputs":[]},{"metadata":{"id":"gAlMLP4ynCxl","colab_type":"text"},"cell_type":"markdown","source":"The following 12 columns are unecessary and will be removed from the data set:\n\n- **vader_min**: no valuable information, will use vader_score instead\n- **vader_max**: no valuable information, will use vader_score instead\n- **vader_sum**: no valuable information, will use vader_score instead\n- **affin_min**: no valuable information, will use affin_score instead\n- **affin_max**: no valuable information, will use affin_score instead\n- **affin_sum**: no valuable information, will use affin_score instead\n- **ol_min**: no valuable information, will use ol_score instead\n- **ol_max**: no valuable information, will use ol_score instead\n- **ol_sum**: no valuable information, will use ol_score instead\n- **ss_min**: no valuable information, will use ss_score instead\n- **ss_max**: no valuable information, will use ss_score instead\n- **ss_sum**: no valuable information, will use ss_score instead"},{"metadata":{"trusted":true,"id":"cx4s8KltnCxm","colab_type":"code","outputId":"5c27ed44-e8d8-411f-bbb6-284a6d3b58d6","colab":{}},"cell_type":"code","source":"df = df.drop(['vader_min','vader_max','vader_sum','afinn_min','afinn_max','afinn_sum','ol_min','ol_max','ol_sum','ss_min','ss_max','ss_sum'], axis=1)\ndf.head()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"522aORJznCxo","colab_type":"code","outputId":"7624719f-c557-4f7b-f8df-ae89f5ba469a","colab":{}},"cell_type":"code","source":"#Show how many (sum) unique values are in the hashtag column\nlen(df['hashtag'].unique().tolist())","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"gbOdj8NsnCxq","colab_type":"code","outputId":"99225144-512e-401f-e4d5-a051b84a96c8","colab":{}},"cell_type":"code","source":"df.info()\n#There all score columns are missing values","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"vblYAM9XnCxr","colab_type":"code","colab":{}},"cell_type":"code","source":"#Fill in missing vader_score with vader_avg score, if available\ndf['vader_score'] = df.apply(\n    lambda row: row['vader_avg'] if np.isnan(row['vader_score']) else row['vader_score'],\n    axis=1\n)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"ywFc_NjGnCxt","colab_type":"code","outputId":"3c10a10d-b42f-4942-a9a9-01ff80423321","colab":{}},"cell_type":"code","source":"df.info()\n#vader_score didn't change","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"hn-EGMgQnCxv","colab_type":"code","colab":{}},"cell_type":"code","source":"#Fill in missing afinn_score with afinn_avg score, if available\ndf['afinn_score'] = df.apply(\n    lambda row: row['afinn_avg'] if np.isnan(row['afinn_score']) else row['afinn_score'],\n    axis=1\n)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"lYgF56z0nCxw","colab_type":"code","outputId":"2b311102-ef0c-4efd-bed1-6b821c79605f","colab":{}},"cell_type":"code","source":"df.info()\n#afinn_score increased from 3867 to 4532","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"8q4SwdsLnCx0","colab_type":"code","colab":{}},"cell_type":"code","source":"#Fill in missing ol_score with ol_avg score, if available\ndf['ol_score'] = df.apply(\n    lambda row: row['ol_avg'] if np.isnan(row['ol_score']) else row['ol_score'],\n    axis=1\n)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"Y-zY0mbRnCx1","colab_type":"code","outputId":"b1fc97dd-5e32-4ad3-828f-2cc65f572358","colab":{}},"cell_type":"code","source":"df.info()\n#ol_score increased from 3867 to 4831","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"oxeMNQponCx3","colab_type":"code","colab":{}},"cell_type":"code","source":"#Fill in missing ss_score with ss_avg score, if available\ndf['ss_score'] = df.apply(\n    lambda row: row['ss_avg'] if np.isnan(row['ss_score']) else row['ss_score'],\n    axis=1\n)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"Q1SpqUXNnCx5","colab_type":"code","outputId":"2e04b1fc-4895-4e9c-9abd-14060695924d","colab":{}},"cell_type":"code","source":"df.info()\n#ss_score increased from 3867 to 4471","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"8j1jpyu6nCx7","colab_type":"code","outputId":"27760da9-cc04-42b4-f81f-45ace5537c8f","colab":{}},"cell_type":"code","source":"#Remove all of the unnecessary scores - ol_score has the highest amount of ratings per hashtag\ndf1 = df.drop(['vader_score','afinn_score','ss_score','vader_avg','afinn_avg','ol_avg','ss_avg'], axis=1)\ndf1.head()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"y362R5B-nCx9","colab_type":"code","outputId":"746c3f05-f5b3-475d-bab4-0adebee8e91c","colab":{}},"cell_type":"code","source":"df1 = df1.dropna(axis = 0, how ='any') \ndf1.info()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"dIbOl7epnCx-","colab_type":"code","outputId":"c5181b40-87c6-4e89-857f-f3348f3f71eb","colab":{}},"cell_type":"code","source":"df1.sort_index(by='hashtag', ascending=[False])","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"Q9HBSRRunCyC","colab_type":"code","outputId":"6c1ef443-a03f-4c82-94a2-7228ca8366b2","colab":{}},"cell_type":"code","source":"#Rename column\ndf1.rename(columns = {'ol_score':'sentiment_score'}, inplace = True)\ndf1.head()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"3_MU82b2qP_M","colab_type":"code","colab":{},"outputId":"ce263170-9e74-4df3-8d7b-5d9c408aa139"},"cell_type":"code","source":"#Show top 10 hashtags with the largest sentiment_score\nx = df1.nlargest(10, 'sentiment_score', keep='all')\nx","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"CEMVT4VxqP_O","colab_type":"code","colab":{},"outputId":"ad2cdf74-ce0a-45a7-fec4-4efd49f586e8"},"cell_type":"code","source":"#Look at dataset by sentiment score counts\ncount = df1.groupby(['sentiment_score']).count() \nprint(count)","execution_count":0,"outputs":[]},{"metadata":{"id":"Uytuuf9unCyG","colab_type":"text"},"cell_type":"markdown","source":"## Load the second dataset\n* Remove null values\n* Remove tracks that were played less than 50 times\n* Merge it with the cleaned df1 dataset (4831 hastags and sentiment scores)"},{"metadata":{"trusted":true,"id":"sdPozOhonCyG","colab_type":"code","outputId":"02c3c306-4ac6-4771-8eb9-2031f306f66b","colab":{}},"cell_type":"code","source":"#Load second dataset\ndf2 = pd.read_csv('../input/nowplayingrs/user_track_hashtag_timestamp.csv')\n\n#Look at size of the dataset\ndf2.shape","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"IGaljC9nnCyK","colab_type":"code","outputId":"3d279bc1-0cf1-470f-f019-79ec31b0ca6d","colab":{}},"cell_type":"code","source":"#Look at the columns and initial rows of the dataset\ndf2.head()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"AMx_kUxdnCyL","colab_type":"code","outputId":"0c7f0981-a89e-4cd3-ccaf-e56061441368","colab":{}},"cell_type":"code","source":"#Check for null values\ndf2.apply(lambda x: x.isnull().sum())","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"kPBEsdKsnCyN","colab_type":"code","outputId":"356171d9-98d2-402d-b1fc-ab3869999e40","colab":{}},"cell_type":"code","source":"#Drop null rows\ndf2.dropna(subset=['hashtag'], inplace=True)\ndf2.apply(lambda x: x.isnull().sum())","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"Q2haAh95nCyO","colab_type":"code","outputId":"51a2c4f8-0f17-493c-fcc3-7a567453bef4","colab":{}},"cell_type":"code","source":"# Get the count of the track_id\ncounts = df2['track_id'].value_counts()\n\n# Select the items where the track_id count is less than 50 and remove them\ndf2 = df2[~df2['track_id'].isin(counts[counts < 50].index)]\n\n# Show info\ndf2.info()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"nH1ESNgPqP_X","colab_type":"code","colab":{},"outputId":"8f078d9b-689b-4c69-fa73-ae3bda9c963e"},"cell_type":"code","source":"df2.user_id.value_counts()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"50uFsgFoqP_a","colab_type":"code","colab":{},"outputId":"7d98c6ab-d09e-445d-94ad-d00a34cc8060"},"cell_type":"code","source":"df2.track_id.value_counts()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"8MVIS7WJnCyQ","colab_type":"code","outputId":"938aad56-e11b-473e-feee-9c5d32bf86c9","colab":{}},"cell_type":"code","source":"#Merge CSV files into a single file based on hashtag\ndf_sentiment = pd.merge(df1, df2, on=\"hashtag\", how='inner')\ndf_sentiment.head()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"4K4k4o22nCyR","colab_type":"code","outputId":"e19d6858-c723-453c-e16c-19659db12261","colab":{}},"cell_type":"code","source":"#Confirm null values in new dataframe\ndf_sentiment.apply(lambda x: x.isnull().sum())","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"8WqmIag8nCyT","colab_type":"code","outputId":"245d046d-922b-4843-9824-19cfa802ff8a","colab":{}},"cell_type":"code","source":"df_sentiment.shape","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"YB8h407WqP_g","colab_type":"code","colab":{},"outputId":"a49cfccc-f6b2-46d8-84ce-1bfdaedefa8d"},"cell_type":"code","source":"df_sentiment.hashtag.value_counts().head(10)","execution_count":0,"outputs":[]},{"metadata":{"id":"GDvHzkARnCyU","colab_type":"text"},"cell_type":"markdown","source":"Now that the two CSV files are joined (inner join), the new dataframe `df_sentiment` is reduced to **5,126,717** rows (from 17,560,114).\n\n## Load the third dataset\n* Remove tracks that were played less than 50 times\n* Remove unnecessary columns\n* Remove null values\n* Reduce the dataset to English only language\n* Merge it with the df_sentiment dataset based on `track_id`, `created_at` and `user_id` columns"},{"metadata":{"trusted":true,"id":"9fqAkHqSnCyV","colab_type":"code","outputId":"15bff8d1-b657-4d01-c158-1ea141c050f6","colab":{}},"cell_type":"code","source":"#Load third dataset and limit it to only load 22 columns\ndf3 = pd.read_csv('../input/nowplayingrs/context_content_features.csv', usecols=range(0, 22))\n\n#Look at size of the dataset\ndf3.shape","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"S_8k9ejUnCyW","colab_type":"code","outputId":"d1f6bb99-c073-4ed9-e626-f61ddfbd8908","colab":{}},"cell_type":"code","source":"# Get the count of the track_id\ncounts = df3['track_id'].value_counts()\n\n# Select the items where the track_id count is less than 50 and remove them\ndf3 = df3[~df3['track_id'].isin(counts[counts < 50].index)]\n\n# Show info\ndf3.info()","execution_count":0,"outputs":[]},{"metadata":{"id":"dAf4MMBvnCyY","colab_type":"text"},"cell_type":"markdown","source":"By removing tracks that were played less than 50 times, the dataset is reduced from 11,614,671 to **9,143,294** rows. The following unnecessary columns will be droped:\n\n- **coordinates**: no valuable information, will use `time_zone` instead\n- **id**: no valuable information, will use `user_id instead\n- **place**: no valuable information, will use `time_zone` instead\n- **geo**: no valuable information, will use `time_zone` instead"},{"metadata":{"trusted":true,"id":"hWrWRfRmnCyZ","colab_type":"code","outputId":"ac25279a-5d55-4218-ac6f-4f592dade846","colab":{}},"cell_type":"code","source":"#Drop unnecessary columns before merging with df_sentiment dataframe\ndf3 = df3.drop(['coordinates','id','place','geo'], axis=1)\ndf3.head()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"T2Bqn9lknCyb","colab_type":"code","outputId":"8cd3393e-6220-46e4-983f-a6aed4f2992f","colab":{}},"cell_type":"code","source":"#Drop all null value rows\ndf3 = df3.dropna()\n\n#Convert mode to Int64\ndf3['mode'] = df3['mode'].astype('Int64')\n\ndf3.shape","execution_count":0,"outputs":[]},{"metadata":{"id":"CoKqjx6DnCyc","colab_type":"text"},"cell_type":"markdown","source":"Reduced the dataset from 10,887,911 to **6,413,576** by dropping all null value rows."},{"metadata":{"trusted":true,"id":"3TK6Agf8nCyd","colab_type":"code","outputId":"69772bcb-adb1-4e74-ded7-38529fc7f7fc","colab":{}},"cell_type":"code","source":"#Limit dataset to only en (English) language\ndf3 = df3.loc[~((df3['lang'] != 'en')),:]\ndf3.info()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"dZlB4Q5hnCye","colab_type":"code","outputId":"288676f8-d401-4afa-a967-91d4f60b4f0f","colab":{}},"cell_type":"code","source":"#Confirm change by looking at the unique values in the lang column\ndf3.lang.unique()","execution_count":0,"outputs":[]},{"metadata":{"id":"XqoSZNUMnCyg","colab_type":"text"},"cell_type":"markdown","source":"Reduced the dataset from 7,740,906 to **4,916,702** by limiting it to English only (lang = en).\n\n### Merge datasets based on track_id, created_at, and user_id"},{"metadata":{"trusted":true,"id":"PzXj5dnwnCyh","colab_type":"code","outputId":"5f460884-8c14-4a19-9d1c-21586522c9b9","colab":{}},"cell_type":"code","source":"#Merge df_sentiment and df3 CSV files into new CSV file based on track_id, created_at and user_id\ndf4 = df_sentiment.merge(df3, on=['track_id','created_at','user_id'], how='inner')\ndf4.head()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"vIU8HApJnCyj","colab_type":"code","outputId":"71d93ddc-b420-4a36-c067-029afb791c88","colab":{}},"cell_type":"code","source":"#Convert hashtag info string\ndf4['hashtag'] = df4['hashtag'].astype(str)\n\n#Convert user_id info string\ndf4['user_id'] = df4['user_id'].astype(str)\n\n#Show changes\ndf4.info()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"cMA4BSFanCyl","colab_type":"code","outputId":"1267dc19-42ba-49f8-db35-482d60288966","colab":{}},"cell_type":"code","source":"#Create new column sentiment that will be the predictor based on the sentiment_score values\ndf4['sentiment'] = np.where(df4['sentiment_score']>= 0.01, 1, 0)\ndf4.head()","execution_count":0,"outputs":[]},{"metadata":{"id":"x4aU51JPL-ql","colab_type":"text"},"cell_type":"markdown","source":"The following unnecessary columns will be droped:\n\n- **hashtag**: no valuable information, will use `sentiment_score` instead\n- **created_at**: no valuable information after the data merge\n- **artist_id**: no valuable information for this model\n- **tweet_lang**: no valuable information for this model\n- **lang**: no valuable information since this dataset has been reduced to English only"},{"metadata":{"trusted":true,"id":"qDeLvtDanCyn","colab_type":"code","outputId":"c7f33dc6-f64c-4c9e-de7e-2bb01a81f35f","colab":{}},"cell_type":"code","source":"#Drop all null value rows\ndf4 = df4.dropna()\n\n#Drop unnecessary columns lang and created_at\ndf4 = df4.drop(['hashtag','created_at','artist_id','tweet_lang','lang'], axis=1)\n\ndf4.head()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"BF_sl6OgL-qn","colab_type":"code","outputId":"a05e361a-bac4-4c49-e298-01ce7322aee3","colab":{}},"cell_type":"code","source":"#Look at unique values for time_zone column\ndf4.time_zone.unique()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"nA67Gv09L-qo","colab_type":"code","colab":{}},"cell_type":"code","source":"#Make all USA Timezone values consistent\ndf4['time_zone'].replace('Eastern Time (US & Canada)', 'Eastern Time',inplace=True)\ndf4['time_zone'].replace('Central Time (US & Canada)', 'Central Time',inplace=True)\ndf4['time_zone'].replace('Pacific Time (US & Canada)', 'Pacific Time',inplace=True)\ndf4['time_zone'].replace('Mountain Time (US & Canada)', 'Mountain Time',inplace=True)\ndf4['time_zone'].replace('Alaska', 'Alaska Time',inplace=True)\ndf4['time_zone'].replace('Hawaii', 'Hawaii Time',inplace=True)\ndf4['time_zone'].replace('Arizona', 'Mountain Time',inplace=True)\ndf4['time_zone'].replace('America/Chicago', 'Central Time',inplace=True)\ndf4['time_zone'].replace('America/New_York', 'Eastern Time',inplace=True)\ndf4['time_zone'].replace('America/Los_Angeles', 'Pacific Time',inplace=True)\ndf4['time_zone'].replace('America/Denver', 'Mountain Time',inplace=True)\ndf4['time_zone'].replace('America/Detroit', 'Eastern Time',inplace=True)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"c3QrUdhAL-qq","colab_type":"code","outputId":"cb3f5347-c113-4dfc-89ed-a94862ca3d38","colab":{}},"cell_type":"code","source":"#Limit dataset to only USA time zones\ndf4 = df4.loc[~((df4['time_zone'] != 'Eastern Time') & (df4['time_zone'] != 'Central Time') & (df4['time_zone'] != 'Pacific Time') & \n               (df4['time_zone'] != 'Mountain Time') & (df4['time_zone'] != 'Alaska Time') & (df4['time_zone'] != 'Hawaii Time')),:]\ndf4.info()","execution_count":0,"outputs":[]},{"metadata":{"id":"Oq4qlcjJL-qs","colab_type":"text"},"cell_type":"markdown","source":"Reduced the dataset from 4,916,702 to **2,267,492** by limiting it to USA Timezone data only.\n\n### Create MVP Dataset\n- Reduced to U.S.A. only dataset\n- **13 feature columns**\n    - sentiment_score: Sentiment score from Opinion Lexicon. If no score was provided then a 0 was input.\n    - user_id: Unique user ID\n    - track_id: Unique track ID\n    - sentiment: Sentiment extracted from sentiment score based on range 0-1\n    - Instrumentalness: Signifies whether a track contains vocals.\n    - Liveness: Presence of an audience in the track recording (range is [0, 1], where 1 indicates high probability of liveness).\n    - Speechiness: Presence of spoken words in a track - whether a track contains more music or words (range is [0, 1], where 0 is a track with no speech).\n    - Danceability: Suitability of a track for dancing based on a combination of musical elements like tempo, rhythm stability, beat strength, and overall regularity (range is [0, 1], where 1 is a most danceable song).\n    - Valence: Musical positiveness conveyed by a track (range is [0, 1], where 1 is a highly positive and cheerful song).\n    - Loudness: The overall loudness of a track in decibel (dB).\n    - Tempo: The overall estimated tempo of a track in beats per minute (BPM).\n    - Acousticness: Probability whether a track is acoustic (range is [0, 1]).\n    - Energy: Perceptual measure of intensity and activity (range is [0, 1], where 1 indicates a high-energy track).\n    - Mode: Modality (major or minor) of a track, i.e., the type of scale from which its melodic content is derived. Major is 1 and minor is 0.\n    - Key: The key that the track is in. Integers map to pitches using standard Pitch Class notation.\n    - tz_Alaska_Time: Categorical - One hot encoded from (dropped) timezone column\n    - tz_Central_Time: Categorical - One hot encoded from (dropped) timezone column\n    - tz_Eastern_Time: Categorical - One hot encoded from (dropped) timezone column\n    - tz_Hawaii_Time: Categorical - One hot encoded from (dropped) timezone column\n    - tz_Mountain_Time: Categorical - One hot encoded from (dropped) timezone column\n    - tz_Pacific_Time: Categorical - One hot encoded from (dropped) timezone column\n    - sentiment: Extracted from `sentiment_score` with a range 0-1 and is the **predictor column**"},{"metadata":{"trusted":true,"id":"3r5gNwzAnCyr","colab_type":"code","outputId":"1420b7e6-e5ee-4230-e32b-1345cc2547ba","colab":{}},"cell_type":"code","source":"# Reorder columns\ndf_mvp = df4[['sentiment','sentiment_score','user_id','track_id','time_zone','instrumentalness',\n              'liveness','speechiness','danceability','valence','loudness','tempo','acousticness','energy','mode','key']]\ndf_mvp.info()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"VSLumBsSL-qw","colab_type":"code","outputId":"f9e039cb-d97d-4fd9-f6c6-ab989c730079","colab":{}},"cell_type":"code","source":"# Create new dataset with only user_id, track_id and time_zone and the category variables\ndf_timezone = df_mvp.drop(['user_id','track_id','sentiment','sentiment_score','instrumentalness','liveness','speechiness',\n                             'danceability','valence','loudness','tempo','acousticness','energy','mode','key'], axis=1)\ndf_timezone.head()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"tyGs0xtcL-qy","colab_type":"code","outputId":"2755b4dd-c2a2-4c36-a9a2-003e780ee2a9","colab":{}},"cell_type":"code","source":"from numpy import array\nfrom numpy import argmax\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\n# One Hot Encode the category data set\none_hot_df = pd.get_dummies(df_timezone)\none_hot_df.head()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"06S4qdwqL-q0","colab_type":"code","outputId":"a2653321-7a01-41e9-b996-6085f0b5d05f","colab":{}},"cell_type":"code","source":"# Rename the columns\none_hot_df.columns = ['tz_Alaska_Time','tz_Central_Time','tz_Eastern_Time','tz_Hawaii_Time','tz_Mountain_Time','tz_Pacific_Time']\none_hot_df.head()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"O6cGX5_VL-q4","colab_type":"code","colab":{}},"cell_type":"code","source":"#Drop time_zone from MVP dataset\ndf_mvp = df_mvp.drop([\"time_zone\"], axis=1)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"-l6arAXeL-q5","colab_type":"code","outputId":"cfc21304-1b2d-46dc-cdf5-125ad97127cb","colab":{}},"cell_type":"code","source":"#Concatenate one hot encoded dataframe\ndf_mvp = pd.concat([df_mvp,one_hot_df], axis=1)\ndf_mvp.head()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"qPTXwr32L-q7","colab_type":"code","colab":{}},"cell_type":"code","source":"df_mvp.to_csv('module4_cleaned.csv',index=False)","execution_count":0,"outputs":[]},{"metadata":{"id":"QpoRdGzAnCys","colab_type":"text"},"cell_type":"markdown","source":"## Explore the data\n\n* Look at the distribution for the data\n* Look for Multicollinearity\n* Remove unnecessary features\n* Balace and scale data"},{"metadata":{"trusted":true,"id":"V0tipToWnCys","colab_type":"code","outputId":"c0095126-7b3f-4a69-e9c5-68914ef2f703","colab":{}},"cell_type":"code","source":"#Look at value counts of the predictor variable sentiment\ndf_mvp.sentiment.value_counts()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"s9DGCrNVnCyu","colab_type":"code","outputId":"d5f25c58-eba7-418f-adb0-df141903de81","colab":{}},"cell_type":"code","source":"# Visualize the predictor variable\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.countplot(x='sentiment', data=df_mvp, palette='hls')\nplt.show()","execution_count":0,"outputs":[]},{"metadata":{"id":"L_KpqcPenCyv","colab_type":"text"},"cell_type":"markdown","source":"**Observation**: The data is very imbalanced and will need to be balanced."},{"metadata":{"trusted":true,"id":"wmzGqdoPnCyx","colab_type":"code","outputId":"1ec8624b-30c5-454d-acd0-c400f294356c","colab":{}},"cell_type":"code","source":"# Create continuous dataset and look at distributions of data\ndf_mvp_lin = df_mvp.drop(['user_id','track_id','sentiment','mode','tz_Alaska_Time','tz_Central_Time','tz_Eastern_Time',\n                          'tz_Hawaii_Time','tz_Mountain_Time','tz_Pacific_Time'], axis=1)\ndf_mvp_lin.hist(figsize = [30, 20]);","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"Ya7aFpBunCyy","colab_type":"code","outputId":"9db1eb83-df70-4b54-8e77-981db994652b","colab":{}},"cell_type":"code","source":"#Create coorelation heatmap and check for multicolinarity\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\ncorrelation = df_mvp_lin.corr()\nplt.figure(figsize=(14, 12))\nheatmap = sns.heatmap(correlation, annot=True, linewidths=0, vmin=-1, cmap=\"RdBu_r\")","execution_count":0,"outputs":[]},{"metadata":{"id":"Bqq5PTIYL-rC","colab_type":"text"},"cell_type":"markdown","source":"**Observation**: Loudness and Energy seem to be highly coorelated.\n\n## Logistic Regression\n* Normalize the data prior to fitting the model\n* Train-Test Split\n* Fit the model\n* Predict\n* Evaluate"},{"metadata":{"trusted":true,"id":"fWpAfHfKnCy1","colab_type":"code","colab":{}},"cell_type":"code","source":"# Define X and y\ny = df_mvp['sentiment']\nX = df_mvp.drop('sentiment', axis = 1)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"UqpSwX30nCy2","colab_type":"code","outputId":"c30ea908-7862-416d-cc25-7fabcb193cca","colab":{}},"cell_type":"code","source":"# Normalizing the data prior to fitting the model.\nx_feats = ['sentiment_score','instrumentalness','liveness','speechiness','danceability',\n           'loudness','tempo','acousticness','energy','mode','key','valence','tz_Alaska_Time',\n           'tz_Central_Time','tz_Eastern_Time','tz_Hawaii_Time','tz_Mountain_Time','tz_Pacific_Time']\n\nX = pd.get_dummies(df_mvp[x_feats], drop_first=False)\ny = df_mvp.sentiment\nX.head()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"gH56DDbSnCy4","colab_type":"code","colab":{}},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Splitting the data into train and test sets (automatically uses stratified sampling by labels)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=42)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"7gWFyQ5fnCy6","colab_type":"code","outputId":"91c675bc-dfa9-4b8b-95dd-44dac085ccdd","colab":{}},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression(fit_intercept = True, C=1e12)\nmodel_log = logreg.fit(X_train, y_train)\nmodel_log","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"KdWbM-1GnCy8","colab_type":"code","outputId":"09107751-70a2-4a34-ef3a-2870d8a2c136","colab":{}},"cell_type":"code","source":"print(y_train.value_counts())\nprint(y_test.value_counts())","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"xcVzA9S-nCy-","colab_type":"code","colab":{},"outputId":"b971816b-c1fd-456c-e3e3-add50e13980c"},"cell_type":"code","source":"#Predict against test set using Sigmoid function\nimport time\nstart = time.time()\n\ny_hat_test = logreg.predict(X_test)\ny_hat_train = logreg.predict(X_train)\n\nend = time.time()\nprint(\"Execution time:\", end - start)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"ieA_DW4dnCzA","colab_type":"code","outputId":"9ccd11f3-c733-47d3-cee3-b7605e2531cc","colab":{}},"cell_type":"code","source":"y_hat_test = logreg.predict_proba(X_test)\ny_hat_test[0]","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"IJf9vWRAnCzB","colab_type":"code","outputId":"441fc013-7d08-43bd-fbfd-cfc5ca48f95b","colab":{}},"cell_type":"code","source":"import time\nstart = time.time()\n\nlogreg.predict_proba(X_train)\n\nend = time.time()\nprint(\"Execution time:\", end - start)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"UCCfZDdknCzD","colab_type":"code","outputId":"a407163f-1768-4f75-8857-9b8ecc9053e0","colab":{}},"cell_type":"code","source":"# How may times was the classifier correct for the training set?\nlogreg.score(X_train, y_train)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"vSa2mlebnCzE","colab_type":"code","outputId":"3fecb6db-51c8-4564-b972-3e0d39b75b64","colab":{}},"cell_type":"code","source":"# How may times was the classifier correct for the test set?\nlogreg.score(X_test, y_test)","execution_count":0,"outputs":[]},{"metadata":{"id":"RQ0wJ7zcnCzH","colab_type":"text"},"cell_type":"markdown","source":"### Classification Model Performance\nCheck the precision, recall, and accuracy of the model."},{"metadata":{"trusted":true,"id":"seES0J89nCzI","colab_type":"code","colab":{}},"cell_type":"code","source":"# Function to calculate the precision\ndef precision(y_hat, y):\n    y_y_hat = list(zip(y, y_hat))\n    tp = sum([1 for i in y_y_hat if i[0]==1 and i[1]==1])\n    fp = sum([1 for i in y_y_hat if i[0]==0 and i[1]==1])\n    return tp/float(tp+fp)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"qmih6t1UnCzJ","colab_type":"code","colab":{}},"cell_type":"code","source":"# Function to calculate the recall\ndef recall(y_hat, y):\n    y_y_hat = list(zip(y, y_hat))\n    tp = sum([1 for i in y_y_hat if i[0]==1 and i[1]==1])\n    fn = sum([1 for i in y_y_hat if i[0]==1 and i[1]==0])\n    return tp/float(tp+fn)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"bRBvVmWHnCzL","colab_type":"code","colab":{}},"cell_type":"code","source":"# Function to calculate the accuracy\ndef accuracy(y_hat, y):\n    y_y_hat = list(zip(y, y_hat))\n    tp = sum([1 for i in y_y_hat if i[0]==1 and i[1]==1])\n    tn = sum([1 for i in y_y_hat if i[0]==0 and i[1]==0])\n    return (tp+tn)/float(len(y_hat))","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"MWDJR3QvnCzM","colab_type":"code","outputId":"748fcc83-37a1-4cc6-e4b6-7c1dde09c45c","colab":{}},"cell_type":"code","source":"# Calculate the precision, recall and accuracy of the classifier.\ny_hat_test = logreg.predict(X_test)\ny_hat_train = logreg.predict(X_train)\n\nprint('Training Precision: ', precision(y_hat_train, y_train))\nprint('Testing Precision: ', precision(y_hat_test, y_test))\nprint('\\n')\n\nprint('Training Recall: ', recall(y_hat_train, y_train))\nprint('Testing Recall: ', recall(y_hat_test, y_test))\nprint('\\n')\n\nprint('Training Accuracy: ', accuracy(y_hat_train, y_train))\nprint('Testing Accuracy: ', accuracy(y_hat_test, y_test))","execution_count":0,"outputs":[]},{"metadata":{"id":"qIHfSd-7L-rZ","colab_type":"text"},"cell_type":"markdown","source":"### Resample data since it's imbalanced and all scores are very high."},{"metadata":{"trusted":true,"id":"0kKDl_mNL-rZ","colab_type":"code","colab":{}},"cell_type":"code","source":"# concatenate our training data back together\ntraining_data = pd.concat([X_train, y_train], axis=1)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"j0M4sff1L-rc","colab_type":"code","colab":{}},"cell_type":"code","source":"# separate minority and majority classes\nnot_safe = training_data[training_data.sentiment==0]\nsafe = training_data[training_data.sentiment==1]","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"DAm6830OL-rd","colab_type":"code","colab":{}},"cell_type":"code","source":"from sklearn.utils import resample\n# upsample minority\nnot_safe_upsampled = resample(not_safe, \n                              replace=True, # sample with replacement\n                              n_samples=len(safe), # match number in majority class\n                              random_state=42) # reproducible results","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"q5-b-LPvL-re","colab_type":"code","colab":{}},"cell_type":"code","source":"# combine majority and upsampled minority\nupsampled = pd.concat([safe, not_safe_upsampled])","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"7w9lU4-cL-rf","colab_type":"code","outputId":"195ccbee-1780-4b79-d5b8-a0f47ed5c29e","colab":{}},"cell_type":"code","source":"# check new class counts\nprint(upsampled.sentiment.value_counts())","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"tBm1_QASL-rg","colab_type":"code","outputId":"850c4f21-817d-4649-c35b-425a345e6a73","colab":{}},"cell_type":"code","source":"sns.countplot(x='sentiment', data=upsampled, palette='hls')\nplt.show()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"rfhOs9odL-rh","colab_type":"code","colab":{}},"cell_type":"code","source":"X_train = upsampled.drop('sentiment', axis=1)\ny_train = upsampled.sentiment","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"NPXnzbNdL-ri","colab_type":"code","outputId":"5ed26ac0-678c-4b1a-f304-b291a7a48d23","colab":{}},"cell_type":"code","source":"# Scaling X using StandardScaler\nfrom sklearn.preprocessing import StandardScaler\n\n# Only fit training data to avoid data leakage\nscaler = StandardScaler()\nX_train = pd.DataFrame(scaler.fit_transform(X_train), columns=list(X.columns))\nX_test = pd.DataFrame(scaler.transform(X_test), columns=list(X.columns))\nX_train.head()","execution_count":0,"outputs":[]},{"metadata":{"id":"2-XMD3PhL-rk","colab_type":"text"},"cell_type":"markdown","source":"### Run another Logistic Regression Model with resampled data"},{"metadata":{"trusted":true,"id":"rurlNgwfL-rl","colab_type":"code","outputId":"c120d21f-aac5-476a-ee3b-83e1e132af0f","colab":{}},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nlogreg2 = LogisticRegression(fit_intercept = True, C=1e12)\nmodel_log = logreg2.fit(X_train, y_train)\nmodel_log","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"Kjt7gxvvL-rm","colab_type":"code","outputId":"62e567d8-400f-4da3-c358-0257573876b5","colab":{}},"cell_type":"code","source":"print(y_train.value_counts())\nprint(y_test.value_counts())","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"v2k_VnuYL-rn","colab_type":"code","colab":{},"outputId":"bcc40020-8b47-4491-dcc2-0f72742a16e2"},"cell_type":"code","source":"# Predict against test set using Sigmoid function\nimport time\nstart = time.time()\n\ny_hat_test = logreg2.predict(X_test)\ny_hat_train = logreg2.predict(X_train)\n\nend = time.time()\nprint(\"Execution time:\", end - start)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"UQMYhYD2L-rq","colab_type":"code","outputId":"9cb9f626-6156-4b47-fef4-a6284bcac0c8","colab":{}},"cell_type":"code","source":"y_hat_test = logreg2.predict_proba(X_test)\ny_hat_test[0]","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"rkEJh4BHL-rs","colab_type":"code","outputId":"904d15fc-206c-45d0-8381-3d065ddb7b2f","colab":{}},"cell_type":"code","source":"import time\nstart = time.time()\n\nlogreg2.predict_proba(X_train)\n\nend = time.time()\nprint(\"Execution time:\", end - start)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"3-GyiDTRL-rt","colab_type":"code","outputId":"2a1d3af2-5189-4b87-f794-8b89c69e7fb3","colab":{}},"cell_type":"code","source":"#Train score\nlogreg2.score(X_train, y_train)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"yOvY9wVhL-ru","colab_type":"code","outputId":"4d2b6cda-1be4-4175-a57b-34ba80758bc6","colab":{}},"cell_type":"code","source":"#Test score\nlogreg2.score(X_test, y_test)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"qco4ty7JL-rv","colab_type":"code","outputId":"9a30ae99-f8bd-4dca-fd39-e767d28d47a1","colab":{}},"cell_type":"code","source":"logreg2.coef_[0]","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"qKqQLa-7L-rw","colab_type":"code","outputId":"30245a51-f658-4d50-e867-f2d64ec345dc","colab":{}},"cell_type":"code","source":"for feature, weight in zip(X.columns, logreg2.coef_[0]):\n    print(\"{} has a weight of : {}\".format(feature, weight))","execution_count":0,"outputs":[]},{"metadata":{"id":"oRCDiuQ3L-rx","colab_type":"text"},"cell_type":"markdown","source":"### Confusion Matrix\n\nShow the performance of the classification model."},{"metadata":{"trusted":true,"id":"eD1q5z4WnCzO","colab_type":"code","outputId":"9ef7e6d0-33af-49b1-e763-d6e1a017a87d","colab":{}},"cell_type":"code","source":"#Create a Confusion Matrix\nfrom sklearn.metrics import confusion_matrix\n\ncnf_matrix = confusion_matrix(y_train, y_hat_train)\nprint('Confusion Matrix:\\n',cnf_matrix)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"jbq8Mk-3nCzP","colab_type":"code","outputId":"a071d458-c663-4c23-c88e-06d2273166f6","colab":{}},"cell_type":"code","source":"#Plot the Confusion Matrix\nimport itertools\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.imshow(cnf_matrix,  cmap=plt.cm.Blues) #Create the basic matrix\n\n#Add title and axis labels\nplt.title('Confusion Matrix')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\n\n#Add appropriate axis scales\nclass_names = set(y) #Get class labels to add to matrix\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names, rotation=45)\nplt.yticks(tick_marks, class_names)\n\n#Add Labels to each cell\nthresh = cnf_matrix.max() / 2. #Used for text coloring below\n#Here we iterate through the confusion matrix and append labels to our visualization\nfor i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n        plt.text(j, i, cnf_matrix[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n\n#Add a side bar legend showing colors\nplt.colorbar()","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"hSF1Of5cqQBA","colab_type":"code","colab":{}},"cell_type":"code","source":"#conf_matrix function\ndef conf_matrix(y_true, y_pred):\n    cm = {'TP': 0, 'TN': 0, 'FP': 0, 'FN': 0}\n    \n    for ind, label in enumerate(y_true):\n        pred = y_pred[ind]\n        if label == 1:\n            # CASE: TP \n            if label == pred:\n                cm['TP'] += 1\n            # CASE: FN\n            else:\n                cm['FN'] += 1\n        else:\n            # CASE: TN\n            if label == pred:\n                cm['TN'] += 1\n            # CASE: FP\n            else:\n                cm['FP'] += 1\n    return cm","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"5UhiwmR2qQBB","colab_type":"code","colab":{}},"cell_type":"code","source":"#Set variable\nmodel_confusion_matrix = conf_matrix(y_train, y_hat_train)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"jKn47vpsqQBC","colab_type":"code","colab":{}},"cell_type":"code","source":"#Precision function\ndef precision(confusion_matrix):\n    return confusion_matrix['TP'] / (confusion_matrix['TP'] + confusion_matrix['FP'])","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"CNDVnr-DqQBE","colab_type":"code","colab":{}},"cell_type":"code","source":"#Recall function\ndef recall(confusion_matrix):\n    return confusion_matrix['TP'] / (confusion_matrix['TP'] + confusion_matrix['FN'])","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"EAQsqqeRqQBE","colab_type":"code","colab":{}},"cell_type":"code","source":"#Accuracy function\ndef accuracy(confusion_matrix):\n    return (confusion_matrix['TP'] + confusion_matrix['TN']) / sum(confusion_matrix.values())","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"H1WG2r8PqQBF","colab_type":"code","colab":{}},"cell_type":"code","source":"#f1 score\ndef f1(confusion_matrix):\n    precision_score = precision(confusion_matrix)\n    recall_score = recall(confusion_matrix)\n    numerator = precision_score * recall_score\n    denominator = precision_score + recall_score\n    return 2 * (numerator / denominator)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"hMyoP-zGqQBG","colab_type":"code","colab":{},"outputId":"e08479b9-b237-4d6e-8c10-96ff9be4ab60"},"cell_type":"code","source":"from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n\npreds = [y_hat_train]\n\nfor ind, i in enumerate(preds):\n    print('-'*40)\n    print('Model Metrics:'.format(ind + 1))\n    print('Precision: {}'.format(precision_score(y_train, i)))\n    print('Recall: {}'.format(recall_score(y_train, i)))\n    print('Accuracy: {}'.format(accuracy_score(y_train, i)))\n    print('F1-Score: {}'.format(f1_score(y_train, i)))","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"gxIYhMSGqQBH","colab_type":"code","colab":{},"outputId":"98254056-ada4-4891-91f2-0510d809c935"},"cell_type":"code","source":"from sklearn.metrics import classification_report\n\nfor ind, i in enumerate(preds):\n    print('-'*40)\n    print(\"Model Classification Report:\".format(ind + 1))\n    print(classification_report(y_train, i))","execution_count":0,"outputs":[]},{"metadata":{"id":"J4IXrteDMtsd","colab_type":"text"},"cell_type":"markdown","source":"## Cross Validation\nRepeat a train-test-split creation 20 times, using a test_size of 0.05."},{"metadata":{"trusted":true,"id":"PEsy9nkWqQBJ","colab_type":"code","colab":{},"outputId":"d21b6bb4-182a-4b07-d739-8ba0907ddf7b"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nlinreg = LinearRegression()\nimport matplotlib.pyplot as plt\n\nnum = 20\ntrain_err = []\ntest_err = []\nfor i in range(num):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n    logreg2.fit(X_train, y_train)\n    y_hat_train = logreg2.predict(X_train)\n    y_hat_test = logreg2.predict(X_test)\n    train_err.append(mean_squared_error(y_train, y_hat_train))\n    test_err.append(mean_squared_error(y_test, y_hat_test))\nplt.scatter(list(range(num)), train_err, label='Training Error')\nplt.scatter(list(range(num)), test_err, label='Testing Error')\nplt.legend();","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"J_P8W2mSqQBK","colab_type":"code","colab":{},"outputId":"0c9b8a71-16da-4e82-ebb9-92ddd58ad83c"},"cell_type":"code","source":"#K-Fold Cross Validation\nfrom sklearn.model_selection import cross_val_score\n\ncv_5_results = np.mean(cross_val_score(logreg2, X, y, cv=5, scoring=\"accuracy\"))\ncv_10_results = np.mean(cross_val_score(logreg2, X, y, cv=10, scoring=\"accuracy\"))\ncv_20_results = np.mean(cross_val_score(logreg2, X, y, cv=20, scoring=\"accuracy\"))\n\nprint(cv_5_results)\nprint(cv_10_results)\nprint(cv_20_results)","execution_count":0,"outputs":[]},{"metadata":{"id":"T8FTNEySL-r1","colab_type":"text"},"cell_type":"markdown","source":"## Create a Sequential Neural Network\n- ReLU activation function\n- Sigmoid function on the output layer "},{"metadata":{"trusted":true,"id":"oWR8x3d1L-r3","colab_type":"code","colab":{},"outputId":"8604551e-a247-4b56-985d-14e88656abc8"},"cell_type":"code","source":"# Load libraries\nfrom numpy import loadtxt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import ModelCheckpoint\n\n# split into input (X) and output (y) variables\nX = pd.get_dummies(df_mvp[x_feats], drop_first=False)\ny = df_mvp.sentiment","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"r0OR6gL5nCzS","colab_type":"code","colab":{}},"cell_type":"code","source":"# define the keras model\nmodel = Sequential()\nmodel.add(Dense(12, input_dim=18, activation='relu'))\nmodel.add(Dense(19, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"U3RBwALtL-r6","colab_type":"code","colab":{}},"cell_type":"code","source":"# compile the keras model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"KHBHfbT2L-r7","colab_type":"code","colab":{}},"cell_type":"code","source":"# Set callback functions to early stop training and save the best model so far\ncheckpoint = [ModelCheckpoint(filepath='models.hdf5', save_best_only=True, monitor='val_loss')]","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"gvBhhejgL-r9","colab_type":"code","outputId":"ce0eadca-c9e3-4e93-a575-366a329366df","colab":{}},"cell_type":"code","source":"# fit the keras model on the dataset\nmodel.fit(X, y, epochs=10, callbacks=checkpoint, batch_size=100)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"Kvf2AxWWL-sA","colab_type":"code","outputId":"fc87557a-8182-467f-d1d5-5d341ccd8674","colab":{}},"cell_type":"code","source":"# evaluate the keras model\n_, accuracy = model.evaluate(X, y)\nprint('Accuracy: %.2f' % (accuracy*100))","execution_count":0,"outputs":[]},{"metadata":{"id":"VsTAEuRbqQBT","colab_type":"text"},"cell_type":"markdown","source":"## Create a Sequential Neural Network with the scaled data\n- ReLU activation function\n- Sigmoid function on the output layer "},{"metadata":{"trusted":true,"id":"ojIfMtATqQBU","colab_type":"code","colab":{}},"cell_type":"code","source":"# split into input (X) and output (y) variables\nX = pd.get_dummies(X_train, drop_first=False) #X_train = upsampled.drop('sentiment', axis=1)\ny = y_train #y_train = upsampled.sentiment","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"3n7DM1OWqQBV","colab_type":"code","colab":{}},"cell_type":"code","source":"# define the keras model\nmodel2 = Sequential()\nmodel2.add(Dense(12, input_dim=18, activation='relu'))\nmodel2.add(Dense(8, activation='relu'))\nmodel2.add(Dense(1, activation='sigmoid'))","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"scXb6rOcqQBW","colab_type":"code","colab":{}},"cell_type":"code","source":"# compile the keras model\nmodel2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"9pyOTHAfqQBX","colab_type":"code","colab":{}},"cell_type":"code","source":"# Set callback functions to early stop training and save the best model so far\ncheckpoint = [ModelCheckpoint(filepath='models.hdf5', save_best_only=True, monitor='val_loss')]","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"1FdWpHr0qQBY","colab_type":"code","colab":{},"outputId":"964ca7c1-fd50-4696-9053-6c03d75c7203"},"cell_type":"code","source":"# fit the keras model on the dataset\nmodel2.fit(X, y, epochs=10, callbacks=checkpoint, batch_size=100)","execution_count":0,"outputs":[]},{"metadata":{"trusted":true,"id":"Na0fLdDgqQBZ","colab_type":"code","colab":{},"outputId":"e1b30fbd-76f1-476f-da97-a7ee6b43dfd6"},"cell_type":"code","source":"# evaluate the keras model\n_, accuracy = model2.evaluate(X, y)\nprint('Accuracy: %.2f' % (accuracy*100))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"student.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":["Uytuuf9unCyG","GDvHzkARnCyU"]}},"nbformat":4,"nbformat_minor":1}