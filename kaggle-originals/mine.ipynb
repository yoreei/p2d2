{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "ur2KW1sdnCxW",
    "outputId": "f584d998-ff68-4aea-8b52-f2159fc35774"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YdiPFmywqP-j"
   },
   "outputs": [],
   "source": [
    "# #import warnings filter\n",
    "# from warnings import simplefilter\n",
    "# # ignore all future warnings\n",
    "# simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "eeqIIUuhnCxd",
    "outputId": "3eb50f87-f84a-4400-a6c0-d1e6843a504b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hashtag        0\n",
       "ol_score    1423\n",
       "ol_avg      2467\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the sentiment_values.csv - The smallest dataset\n",
    "df = pd.read_csv('../data/chelseapower/fixed_sentiment_values.csv')\n",
    "\n",
    "#Look at size of the dataset\n",
    "df = df[['hashtag', 'ol_score', 'ol_avg']]\n",
    "df.apply(lambda x: x.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8q4SwdsLnCx0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hashtag        0\n",
       "ol_score     459\n",
       "ol_avg      2467\n",
       "dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fill in missing ol_score with ol_avg score, if available\n",
    "df['ol_score'] = df.apply(\n",
    "    lambda row: row['ol_avg'] if np.isnan(row['ol_score']) else row['ol_score'],\n",
    "    axis=1\n",
    ")\n",
    "df.apply(lambda x: x.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y362R5B-nCx9",
    "outputId": "746c3f05-f5b3-475d-bab4-0adebee8e91c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2823 entries, 1 to 5289\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   hashtag   2823 non-null   object \n",
      " 1   ol_score  2823 non-null   float64\n",
      " 2   ol_avg    2823 non-null   float64\n",
      "dtypes: float64(2), object(1)\n",
      "memory usage: 88.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df1 = df.dropna(axis = 0, how ='any') \n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dIbOl7epnCx-",
    "outputId": "c5181b40-87c6-4e89-857f-f3348f3f71eb"
   },
   "outputs": [],
   "source": [
    "# df1.sort_index(by='hashtag', ascending=[False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q9HBSRRunCyC",
    "outputId": "6c1ef443-a03f-4c82-94a2-7228ca8366b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ssdapps\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py:4441: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>ol_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>melovechilicheese</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>greatmusic</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amonamarth</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>againbecauseitissogood</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cloudnine</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  hashtag  sentiment_score  ol_avg\n",
       "1       melovechilicheese              0.8     1.0\n",
       "2              greatmusic              2.4     1.0\n",
       "4              amonamarth              0.3     0.0\n",
       "5  againbecauseitissogood              0.7     1.0\n",
       "6               cloudnine              0.0     0.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Rename column\n",
    "df1.rename(columns = {'ol_score':'sentiment_score'}, inplace = True)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3_MU82b2qP_M",
    "outputId": "ce263170-9e74-4df3-8d7b-5d9c408aa139"
   },
   "outputs": [],
   "source": [
    "# #Show top 10 hashtags with the largest sentiment_score\n",
    "# x = df1.nlargest(10, 'sentiment_score')\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sdPozOhonCyG",
    "outputId": "02c3c306-4ac6-4771-8eb9-2031f306f66b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17560113, 4)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load second dataset\n",
    "df2 = pd.read_csv('../data/chelseapower/user_track_hashtag_timestamp.csv')\n",
    "\n",
    "#Look at size of the dataset\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IGaljC9nnCyK",
    "outputId": "3d279bc1-0cf1-470f-f019-79ec31b0ca6d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>track_id</th>\n",
       "      <th>hashtag</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81496937</td>\n",
       "      <td>cd52b3e5b51da29e5893dba82a418a4b</td>\n",
       "      <td>nowplaying</td>\n",
       "      <td>2014-01-01 05:54:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81496937</td>\n",
       "      <td>cd52b3e5b51da29e5893dba82a418a4b</td>\n",
       "      <td>goth</td>\n",
       "      <td>2014-01-01 05:54:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81496937</td>\n",
       "      <td>cd52b3e5b51da29e5893dba82a418a4b</td>\n",
       "      <td>deathrock</td>\n",
       "      <td>2014-01-01 05:54:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81496937</td>\n",
       "      <td>cd52b3e5b51da29e5893dba82a418a4b</td>\n",
       "      <td>postpunk</td>\n",
       "      <td>2014-01-01 05:54:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2205686924</td>\n",
       "      <td>da3110a77b724072b08f231c9d6f7534</td>\n",
       "      <td>NowPlaying</td>\n",
       "      <td>2014-01-01 05:54:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                          track_id     hashtag  \\\n",
       "0    81496937  cd52b3e5b51da29e5893dba82a418a4b  nowplaying   \n",
       "1    81496937  cd52b3e5b51da29e5893dba82a418a4b        goth   \n",
       "2    81496937  cd52b3e5b51da29e5893dba82a418a4b   deathrock   \n",
       "3    81496937  cd52b3e5b51da29e5893dba82a418a4b    postpunk   \n",
       "4  2205686924  da3110a77b724072b08f231c9d6f7534  NowPlaying   \n",
       "\n",
       "            created_at  \n",
       "0  2014-01-01 05:54:21  \n",
       "1  2014-01-01 05:54:21  \n",
       "2  2014-01-01 05:54:21  \n",
       "3  2014-01-01 05:54:21  \n",
       "4  2014-01-01 05:54:22  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at the columns and initial rows of the dataset\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMx_kUxdnCyL",
    "outputId": "0c7f0981-a89e-4cd3-ccaf-e56061441368"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id       0\n",
       "track_id      0\n",
       "hashtag       1\n",
       "created_at    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for null values\n",
    "df2.apply(lambda x: x.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kPBEsdKsnCyN",
    "outputId": "356171d9-98d2-402d-b1fc-ab3869999e40"
   },
   "outputs": [],
   "source": [
    "#Drop null rows\n",
    "df2 = df2.dropna(subset=['hashtag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q2haAh95nCyO",
    "outputId": "51a2c4f8-0f17-493c-fcc3-7a567453bef4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14966614 entries, 0 to 17560112\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Dtype \n",
      "---  ------      ----- \n",
      " 0   user_id     int64 \n",
      " 1   track_id    object\n",
      " 2   hashtag     object\n",
      " 3   created_at  object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 570.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# Get the count of the track_id\n",
    "counts = df2['track_id'].value_counts()\n",
    "\n",
    "# Select the items where the track_id count is less than 50 and remove them\n",
    "df2 = df2[~df2['track_id'].isin(counts[counts < 50].index)]\n",
    "\n",
    "# Show info\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8MVIS7WJnCyQ",
    "outputId": "938aad56-e11b-473e-feee-9c5d32bf86c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>ol_avg</th>\n",
       "      <th>user_id</th>\n",
       "      <th>track_id</th>\n",
       "      <th>created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greatmusic</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>252330820</td>\n",
       "      <td>8f2ac86abb8bd48273c8fc95b632e347</td>\n",
       "      <td>2014-02-13 16:18:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>greatmusic</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29235188</td>\n",
       "      <td>45bbd6d7cd65dc77596af8c5c0b89a70</td>\n",
       "      <td>2014-05-15 20:38:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>greatmusic</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2308582644</td>\n",
       "      <td>fca4f99723ab8f66d00d8b069c7daced</td>\n",
       "      <td>2014-06-14 00:21:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>greatmusic</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>954234692</td>\n",
       "      <td>6d45097acaaf6ed5ee55041f53249fa0</td>\n",
       "      <td>2014-10-22 18:33:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>greatmusic</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>195485165</td>\n",
       "      <td>6d45097acaaf6ed5ee55041f53249fa0</td>\n",
       "      <td>2014-10-22 18:36:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      hashtag  sentiment_score  ol_avg     user_id  \\\n",
       "0  greatmusic              2.4     1.0   252330820   \n",
       "1  greatmusic              2.4     1.0    29235188   \n",
       "2  greatmusic              2.4     1.0  2308582644   \n",
       "3  greatmusic              2.4     1.0   954234692   \n",
       "4  greatmusic              2.4     1.0   195485165   \n",
       "\n",
       "                           track_id           created_at  \n",
       "0  8f2ac86abb8bd48273c8fc95b632e347  2014-02-13 16:18:51  \n",
       "1  45bbd6d7cd65dc77596af8c5c0b89a70  2014-05-15 20:38:46  \n",
       "2  fca4f99723ab8f66d00d8b069c7daced  2014-06-14 00:21:19  \n",
       "3  6d45097acaaf6ed5ee55041f53249fa0  2014-10-22 18:33:52  \n",
       "4  6d45097acaaf6ed5ee55041f53249fa0  2014-10-22 18:36:54  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge CSV files into a single file based on hashtag\n",
    "df_sentiment = pd.merge(df1, df2, on=\"hashtag\", how='inner')\n",
    "df_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4K4k4o22nCyR",
    "outputId": "e19d6858-c723-453c-e16c-19659db12261"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hashtag            0\n",
       "sentiment_score    0\n",
       "ol_avg             0\n",
       "user_id            0\n",
       "track_id           0\n",
       "created_at         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm null values in new dataframe\n",
    "df_sentiment.apply(lambda x: x.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WqmIag8nCyT",
    "outputId": "245d046d-922b-4843-9824-19cfa802ff8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138021, 6)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YB8h407WqP_g",
    "outputId": "a49cfccc-f6b2-46d8-84ce-1bfdaedefa8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "postpunk           25299\n",
       "punk               24730\n",
       "deathrock          24699\n",
       "tophits            22836\n",
       "doommetal           4296\n",
       "freshoutthebox      3997\n",
       "realclassicrock     2473\n",
       "slamhardstyle       2331\n",
       "freshlysqueezed     2154\n",
       "chill               2112\n",
       "Name: hashtag, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment.hashtag.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDvHzkARnCyU"
   },
   "source": [
    "Now that the two CSV files are joined (inner join), the new dataframe `df_sentiment` is reduced to **5,126,717** rows (from 17,560,114).\n",
    "\n",
    "## Load the third dataset\n",
    "* Remove tracks that were played less than 50 times\n",
    "* Remove unnecessary columns\n",
    "* Remove null values\n",
    "* Reduce the dataset to English only language\n",
    "* Merge it with the df_sentiment dataset based on `track_id`, `created_at` and `user_id` columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fqAkHqSnCyV",
    "outputId": "15bff8d1-b657-4d01-c158-1ea141c050f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11614671, 22)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load third dataset and limit it to only load 22 columns\n",
    "df3 = pd.read_csv('../data/chelseapower/fixed_context_content_features.csv')\n",
    "\n",
    "#Look at size of the dataset\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_8k9ejUnCyW",
    "outputId": "d1f6bb99-c073-4ed9-e626-f61ddfbd8908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9143294 entries, 1 to 11614670\n",
      "Data columns (total 22 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   coordinates       object \n",
      " 1   instrumentalness  float64\n",
      " 2   liveness          float64\n",
      " 3   speechiness       float64\n",
      " 4   danceability      float64\n",
      " 5   valence           float64\n",
      " 6   loudness          float64\n",
      " 7   tempo             float64\n",
      " 8   acousticness      float64\n",
      " 9   energy            float64\n",
      " 10  mode              float64\n",
      " 11  key               float64\n",
      " 12  artist_id         object \n",
      " 13  place             object \n",
      " 14  geo               object \n",
      " 15  tweet_lang        object \n",
      " 16  track_id          object \n",
      " 17  created_at        object \n",
      " 18  lang              object \n",
      " 19  time_zone         object \n",
      " 20  user_id           float64\n",
      " 21  id                int64  \n",
      "dtypes: float64(12), int64(1), object(9)\n",
      "memory usage: 1.6+ GB\n"
     ]
    }
   ],
   "source": [
    "# Get the count of the track_id\n",
    "counts = df3['track_id'].value_counts()\n",
    "\n",
    "# Select the items where the track_id count is less than 50 and remove them\n",
    "df3 = df3[~df3['track_id'].isin(counts[counts < 50].index)]\n",
    "\n",
    "# Show info\n",
    "df3.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dAf4MMBvnCyY"
   },
   "source": [
    "By removing tracks that were played less than 50 times, the dataset is reduced from 11,614,671 to **9,143,294** rows. The following unnecessary columns will be droped:\n",
    "\n",
    "- **coordinates**: no valuable information, will use `time_zone` instead\n",
    "- **id**: no valuable information, will use `user_id instead\n",
    "- **place**: no valuable information, will use `time_zone` instead\n",
    "- **geo**: no valuable information, will use `time_zone` instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWrWRfRmnCyZ",
    "outputId": "ac25279a-5d55-4218-ac6f-4f592dade846"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>valence</th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>energy</th>\n",
       "      <th>mode</th>\n",
       "      <th>key</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>tweet_lang</th>\n",
       "      <th>track_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>time_zone</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.017700</td>\n",
       "      <td>0.0638</td>\n",
       "      <td>0.0624</td>\n",
       "      <td>0.769</td>\n",
       "      <td>0.752</td>\n",
       "      <td>-8.252</td>\n",
       "      <td>95.862</td>\n",
       "      <td>0.2670</td>\n",
       "      <td>0.826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5cddcd0e314e2f2223ab21937d2c8778</td>\n",
       "      <td>en</td>\n",
       "      <td>da3110a77b724072b08f231c9d6f7534</td>\n",
       "      <td>2014-01-01 05:54:22</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.205687e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.775</td>\n",
       "      <td>-4.432</td>\n",
       "      <td>97.030</td>\n",
       "      <td>0.2170</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>e41273f43af504714d85465294f1f369</td>\n",
       "      <td>en</td>\n",
       "      <td>ba84d88c10fb0e42d4754a27ead10546</td>\n",
       "      <td>2014-01-01 05:54:22</td>\n",
       "      <td>es</td>\n",
       "      <td>Mountain Time (US &amp; Canada)</td>\n",
       "      <td>1.325884e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.333</td>\n",
       "      <td>-5.647</td>\n",
       "      <td>74.101</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>557ce373bd29743eb00a3723ab19ebe8</td>\n",
       "      <td>en</td>\n",
       "      <td>33f95122281f76e7134f9cbea3be980f</td>\n",
       "      <td>2014-01-01 05:54:24</td>\n",
       "      <td>en</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>9.767522e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.912</td>\n",
       "      <td>-4.271</td>\n",
       "      <td>93.010</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>0.787</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>f965ec352eb8c0efc0af46244754942f</td>\n",
       "      <td>en</td>\n",
       "      <td>8bd5206b84c968eda0af8bc86d6ab1d1</td>\n",
       "      <td>2014-01-01 05:54:25</td>\n",
       "      <td>en</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "      <td>4.522857e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.3620</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.677</td>\n",
       "      <td>-4.271</td>\n",
       "      <td>126.045</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>a3abd1e016fdba82a91379b7e2b9ab69</td>\n",
       "      <td>en</td>\n",
       "      <td>23ced06ca57d37fa749b1595bc7ed1a4</td>\n",
       "      <td>2014-01-01 05:54:28</td>\n",
       "      <td>en</td>\n",
       "      <td>Quito</td>\n",
       "      <td>6.508628e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instrumentalness  liveness  speechiness  danceability  valence  loudness  \\\n",
       "1          0.017700    0.0638       0.0624         0.769    0.752    -8.252   \n",
       "2          0.000000    0.0860       0.0436         0.675    0.775    -4.432   \n",
       "3          0.000000    0.1430       0.0292         0.324    0.333    -5.647   \n",
       "5          0.000000    0.1100       0.0375         0.641    0.912    -4.271   \n",
       "6          0.000006    0.3620       0.1340         0.554    0.677    -4.271   \n",
       "\n",
       "     tempo  acousticness  energy  mode  key                         artist_id  \\\n",
       "1   95.862        0.2670   0.826   1.0  7.0  5cddcd0e314e2f2223ab21937d2c8778   \n",
       "2   97.030        0.2170   0.885   0.0  1.0  e41273f43af504714d85465294f1f369   \n",
       "3   74.101        0.2390   0.574   1.0  7.0  557ce373bd29743eb00a3723ab19ebe8   \n",
       "5   93.010        0.0268   0.787   1.0  0.0  f965ec352eb8c0efc0af46244754942f   \n",
       "6  126.045        0.0216   0.878   1.0  3.0  a3abd1e016fdba82a91379b7e2b9ab69   \n",
       "\n",
       "  tweet_lang                          track_id           created_at lang  \\\n",
       "1         en  da3110a77b724072b08f231c9d6f7534  2014-01-01 05:54:22   en   \n",
       "2         en  ba84d88c10fb0e42d4754a27ead10546  2014-01-01 05:54:22   es   \n",
       "3         en  33f95122281f76e7134f9cbea3be980f  2014-01-01 05:54:24   en   \n",
       "5         en  8bd5206b84c968eda0af8bc86d6ab1d1  2014-01-01 05:54:25   en   \n",
       "6         en  23ced06ca57d37fa749b1595bc7ed1a4  2014-01-01 05:54:28   en   \n",
       "\n",
       "                     time_zone       user_id  \n",
       "1                          NaN  2.205687e+09  \n",
       "2  Mountain Time (US & Canada)  1.325884e+08  \n",
       "3   Eastern Time (US & Canada)  9.767522e+07  \n",
       "5   Central Time (US & Canada)  4.522857e+08  \n",
       "6                        Quito  6.508628e+07  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop unnecessary columns before merging with df_sentiment dataframe\n",
    "df3 = df3.drop(['coordinates','id','place','geo'], axis=1)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instrumentalness       2601\n",
       "liveness               2601\n",
       "speechiness            3158\n",
       "danceability           3158\n",
       "valence                3976\n",
       "loudness                  0\n",
       "tempo                     0\n",
       "acousticness           2601\n",
       "energy                 2601\n",
       "mode                   2601\n",
       "key                    2601\n",
       "artist_id                 0\n",
       "tweet_lang                0\n",
       "track_id                  0\n",
       "created_at                0\n",
       "lang                      0\n",
       "time_zone           2689681\n",
       "user_id               38025\n",
       "dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.apply(lambda x: x.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T2Bqn9lknCyb",
    "outputId": "8cd3393e-6220-46e4-983f-a6aed4f2992f"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "['danceability ', 'valence ', 'acousticness ', 'energy ', 'mode ', 'key ', 'time_zone ', 'user_id ']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-65079d1d2212>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Drop all null value rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m df3 = df3.dropna(subset=\n\u001b[0m\u001b[0;32m      3\u001b[0m                  ['instrumentalness', 'liveness', 'speechiness', 'danceability ',\n\u001b[0;32m      4\u001b[0m                   \u001b[1;34m'valence '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'acousticness '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'energy '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mode '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'key '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                   'time_zone ', 'user_id '])\n",
      "\u001b[1;32mE:\\ssdapps\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdropna\u001b[1;34m(self, axis, how, thresh, subset, inplace)\u001b[0m\n\u001b[0;32m   5160\u001b[0m             \u001b[0mcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5161\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5162\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5163\u001b[0m             \u001b[0magg_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0magg_axis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ['danceability ', 'valence ', 'acousticness ', 'energy ', 'mode ', 'key ', 'time_zone ', 'user_id ']"
     ]
    }
   ],
   "source": [
    "#Drop all null value rows\n",
    "df3 = df3.dropna(subset=\n",
    "                 ['instrumentalness', 'liveness', 'speechiness', 'danceability ',\n",
    "                  'valence ', 'acousticness ', 'energy ', 'mode ', 'key ',\n",
    "                  'time_zone ', 'user_id '])\n",
    "#Convert mode to Int64\n",
    "df3['mode'] = df3['mode'].astype('Int64')\n",
    "\n",
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.apply(lambda x: x.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CoKqjx6DnCyc"
   },
   "source": [
    "Reduced the dataset from 10,887,911 to **6,413,576** by dropping all null value rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3TK6Agf8nCyd",
    "outputId": "69772bcb-adb1-4e74-ded7-38529fc7f7fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4916702 entries, 3 to 11614670\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   instrumentalness  float64\n",
      " 1   liveness          float64\n",
      " 2   speechiness       float64\n",
      " 3   danceability      float64\n",
      " 4   valence           float64\n",
      " 5   loudness          float64\n",
      " 6   tempo             float64\n",
      " 7   acousticness      float64\n",
      " 8   energy            float64\n",
      " 9   mode              Int64  \n",
      " 10  key               float64\n",
      " 11  artist_id         object \n",
      " 12  tweet_lang        object \n",
      " 13  track_id          object \n",
      " 14  created_at        object \n",
      " 15  lang              object \n",
      " 16  time_zone         object \n",
      " 17  user_id           float64\n",
      "dtypes: Int64(1), float64(11), object(6)\n",
      "memory usage: 717.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#Limit dataset to only en (English) language\n",
    "df3 = df3.loc[~((df3['lang'] != 'en')),:]\n",
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dZlB4Q5hnCye",
    "outputId": "288676f8-d401-4afa-a967-91d4f60b4f0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Confirm change by looking at the unique values in the lang column\n",
    "df3.lang.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XqoSZNUMnCyg"
   },
   "source": [
    "Reduced the dataset from 7,740,906 to **4,916,702** by limiting it to English only (lang = en).\n",
    "\n",
    "### Merge datasets based on track_id, created_at, and user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzXj5dnwnCyh",
    "outputId": "5f460884-8c14-4a19-9d1c-21586522c9b9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtag</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>ol_avg</th>\n",
       "      <th>user_id</th>\n",
       "      <th>track_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>...</th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>energy</th>\n",
       "      <th>mode</th>\n",
       "      <th>key</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>tweet_lang</th>\n",
       "      <th>lang</th>\n",
       "      <th>time_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>greatmusic</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>252330820</td>\n",
       "      <td>8f2ac86abb8bd48273c8fc95b632e347</td>\n",
       "      <td>2014-02-13 16:18:51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.1690</td>\n",
       "      <td>0.461</td>\n",
       "      <td>...</td>\n",
       "      <td>-9.046</td>\n",
       "      <td>143.055</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1a17d5f8af99355edd8a92679a02cb0d</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>greatmusic</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29235188</td>\n",
       "      <td>45bbd6d7cd65dc77596af8c5c0b89a70</td>\n",
       "      <td>2014-05-15 20:38:46</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>0.677</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.237</td>\n",
       "      <td>77.837</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4a4e2ab094a4521b06252e9fdaf1fd0a</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>classic</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29235188</td>\n",
       "      <td>45bbd6d7cd65dc77596af8c5c0b89a70</td>\n",
       "      <td>2014-05-15 20:38:46</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.0451</td>\n",
       "      <td>0.677</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.237</td>\n",
       "      <td>77.837</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4a4e2ab094a4521b06252e9fdaf1fd0a</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>greatmusic</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>195485165</td>\n",
       "      <td>6d45097acaaf6ed5ee55041f53249fa0</td>\n",
       "      <td>2014-10-22 18:36:54</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.591</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.315</td>\n",
       "      <td>100.063</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.746</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>f78fb5a7ddce990521f685522f3f8fce</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>London</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>amonamarth</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124052165</td>\n",
       "      <td>d53b2de022666067050dae8f6645edc2</td>\n",
       "      <td>2014-09-26 16:06:48</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.0709</td>\n",
       "      <td>0.355</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.054</td>\n",
       "      <td>130.427</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>942c9f2520684c22eb6216a92b711f9e</td>\n",
       "      <td>en</td>\n",
       "      <td>en</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      hashtag  sentiment_score  ol_avg    user_id  \\\n",
       "0  greatmusic              2.4     1.0  252330820   \n",
       "1  greatmusic              2.4     1.0   29235188   \n",
       "2     classic              1.0     1.0   29235188   \n",
       "3  greatmusic              2.4     1.0  195485165   \n",
       "4  amonamarth              0.3     0.0  124052165   \n",
       "\n",
       "                           track_id           created_at  instrumentalness  \\\n",
       "0  8f2ac86abb8bd48273c8fc95b632e347  2014-02-13 16:18:51          0.000000   \n",
       "1  45bbd6d7cd65dc77596af8c5c0b89a70  2014-05-15 20:38:46          0.000010   \n",
       "2  45bbd6d7cd65dc77596af8c5c0b89a70  2014-05-15 20:38:46          0.000010   \n",
       "3  6d45097acaaf6ed5ee55041f53249fa0  2014-10-22 18:36:54          0.000000   \n",
       "4  d53b2de022666067050dae8f6645edc2  2014-09-26 16:06:48          0.000142   \n",
       "\n",
       "   liveness  speechiness  danceability  ...  loudness    tempo  acousticness  \\\n",
       "0    0.1980       0.1690         0.461  ...    -9.046  143.055      0.100000   \n",
       "1    0.0454       0.0451         0.677  ...   -13.237   77.837      0.031300   \n",
       "2    0.0454       0.0451         0.677  ...   -13.237   77.837      0.031300   \n",
       "3    0.0769       0.0427         0.591  ...    -6.315  100.063      0.017100   \n",
       "4    0.1130       0.0709         0.355  ...    -4.054  130.427      0.000004   \n",
       "\n",
       "   energy  mode   key                         artist_id tweet_lang lang  \\\n",
       "0   0.628     0   4.0  1a17d5f8af99355edd8a92679a02cb0d         en   en   \n",
       "1   0.544     0  11.0  4a4e2ab094a4521b06252e9fdaf1fd0a         en   en   \n",
       "2   0.544     0  11.0  4a4e2ab094a4521b06252e9fdaf1fd0a         en   en   \n",
       "3   0.746     1  11.0  f78fb5a7ddce990521f685522f3f8fce         en   en   \n",
       "4   0.980     0   7.0  942c9f2520684c22eb6216a92b711f9e         en   en   \n",
       "\n",
       "                    time_zone  \n",
       "0  Eastern Time (US & Canada)  \n",
       "1  Eastern Time (US & Canada)  \n",
       "2  Eastern Time (US & Canada)  \n",
       "3                      London  \n",
       "4                      Alaska  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Merge df_sentiment and df3 CSV files into new CSV file based on track_id, created_at and user_id\n",
    "df4 = df_sentiment.merge(df3, on=['track_id','created_at','user_id'], how='inner')\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vIU8HApJnCyj",
    "outputId": "71d93ddc-b420-4a36-c067-029afb791c88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 69428 entries, 0 to 69427\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   hashtag           69428 non-null  object \n",
      " 1   sentiment_score   69428 non-null  float64\n",
      " 2   ol_avg            69428 non-null  float64\n",
      " 3   user_id           69428 non-null  object \n",
      " 4   track_id          69428 non-null  object \n",
      " 5   created_at        69428 non-null  object \n",
      " 6   instrumentalness  69428 non-null  float64\n",
      " 7   liveness          69428 non-null  float64\n",
      " 8   speechiness       69428 non-null  float64\n",
      " 9   danceability      69428 non-null  float64\n",
      " 10  valence           69428 non-null  float64\n",
      " 11  loudness          69428 non-null  float64\n",
      " 12  tempo             69428 non-null  float64\n",
      " 13  acousticness      69428 non-null  float64\n",
      " 14  energy            69428 non-null  float64\n",
      " 15  mode              69428 non-null  Int64  \n",
      " 16  key               69428 non-null  float64\n",
      " 17  artist_id         69428 non-null  object \n",
      " 18  tweet_lang        69428 non-null  object \n",
      " 19  lang              69428 non-null  object \n",
      " 20  time_zone         69428 non-null  object \n",
      "dtypes: Int64(1), float64(12), object(8)\n",
      "memory usage: 11.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#Convert hashtag info string\n",
    "df4['hashtag'] = df4['hashtag'].astype(str)\n",
    "\n",
    "#Convert user_id info string\n",
    "df4['user_id'] = df4['user_id'].astype(str)\n",
    "\n",
    "#Show changes\n",
    "df4.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cMA4BSFanCyl",
    "outputId": "1267dc19-42ba-49f8-db35-482d60288966"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hashtag            0\n",
       "sentiment_score    0\n",
       "ol_avg             0\n",
       "user_id            0\n",
       "track_id           0\n",
       "created_at         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create new column sentiment that will be the predictor based on the sentiment_score values\n",
    "df4['sentiment'] = np.where(df4['sentiment_score']>= 0.01, 1, 0)\n",
    "df4.head()\n",
    "#Confirm null values in new dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hashtag             0\n",
       "sentiment_score     0\n",
       "ol_avg              0\n",
       "user_id             0\n",
       "track_id            0\n",
       "created_at          0\n",
       "instrumentalness    0\n",
       "liveness            0\n",
       "speechiness         0\n",
       "danceability        0\n",
       "valence             0\n",
       "loudness            0\n",
       "tempo               0\n",
       "acousticness        0\n",
       "energy              0\n",
       "mode                0\n",
       "key                 0\n",
       "artist_id           0\n",
       "tweet_lang          0\n",
       "lang                0\n",
       "time_zone           0\n",
       "sentiment           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.apply(lambda x: x.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x4aU51JPL-ql"
   },
   "source": [
    "The following unnecessary columns will be droped:\n",
    "\n",
    "- **hashtag**: no valuable information, will use `sentiment_score` instead\n",
    "- **created_at**: no valuable information after the data merge\n",
    "- **artist_id**: no valuable information for this model\n",
    "- **tweet_lang**: no valuable information for this model\n",
    "- **lang**: no valuable information since this dataset has been reduced to English only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qDeLvtDanCyn",
    "outputId": "c7f33dc6-f64c-4c9e-de7e-2bb01a81f35f"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Drop unnecessary columns lang and created_at\n",
    "df4 = df4.drop(['hashtag','created_at','artist_id','tweet_lang','lang'], axis=1)\n",
    "\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BF_sl6OgL-qn",
    "outputId": "a05e361a-bac4-4c49-e298-01ce7322aee3"
   },
   "outputs": [],
   "source": [
    "#Look at unique values for time_zone column\n",
    "df4.time_zone.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nA67Gv09L-qo"
   },
   "outputs": [],
   "source": [
    "#Make all USA Timezone values consistent\n",
    "df4['time_zone'].replace('Eastern Time (US & Canada)', 'Eastern Time',inplace=True)\n",
    "df4['time_zone'].replace('Central Time (US & Canada)', 'Central Time',inplace=True)\n",
    "df4['time_zone'].replace('Pacific Time (US & Canada)', 'Pacific Time',inplace=True)\n",
    "df4['time_zone'].replace('Mountain Time (US & Canada)', 'Mountain Time',inplace=True)\n",
    "df4['time_zone'].replace('Alaska', 'Alaska Time',inplace=True)\n",
    "df4['time_zone'].replace('Hawaii', 'Hawaii Time',inplace=True)\n",
    "df4['time_zone'].replace('Arizona', 'Mountain Time',inplace=True)\n",
    "df4['time_zone'].replace('America/Chicago', 'Central Time',inplace=True)\n",
    "df4['time_zone'].replace('America/New_York', 'Eastern Time',inplace=True)\n",
    "df4['time_zone'].replace('America/Los_Angeles', 'Pacific Time',inplace=True)\n",
    "df4['time_zone'].replace('America/Denver', 'Mountain Time',inplace=True)\n",
    "df4['time_zone'].replace('America/Detroit', 'Eastern Time',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c3QrUdhAL-qq",
    "outputId": "cb3f5347-c113-4dfc-89ed-a94862ca3d38"
   },
   "outputs": [],
   "source": [
    "#Limit dataset to only USA time zones\n",
    "df4 = df4.loc[~((df4['time_zone'] != 'Eastern Time') & (df4['time_zone'] != 'Central Time') & (df4['time_zone'] != 'Pacific Time') & \n",
    "               (df4['time_zone'] != 'Mountain Time') & (df4['time_zone'] != 'Alaska Time') & (df4['time_zone'] != 'Hawaii Time')),:]\n",
    "df4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Oq4qlcjJL-qs"
   },
   "source": [
    "Reduced the dataset from 4,916,702 to **2,267,492** by limiting it to USA Timezone data only.\n",
    "\n",
    "### Create MVP Dataset\n",
    "- Reduced to U.S.A. only dataset\n",
    "- **13 feature columns**\n",
    "    - sentiment_score: Sentiment score from Opinion Lexicon. If no score was provided then a 0 was input.\n",
    "    - user_id: Unique user ID\n",
    "    - track_id: Unique track ID\n",
    "    - sentiment: Sentiment extracted from sentiment score based on range 0-1\n",
    "    - Instrumentalness: Signifies whether a track contains vocals.\n",
    "    - Liveness: Presence of an audience in the track recording (range is [0, 1], where 1 indicates high probability of liveness).\n",
    "    - Speechiness: Presence of spoken words in a track - whether a track contains more music or words (range is [0, 1], where 0 is a track with no speech).\n",
    "    - Danceability: Suitability of a track for dancing based on a combination of musical elements like tempo, rhythm stability, beat strength, and overall regularity (range is [0, 1], where 1 is a most danceable song).\n",
    "    - Valence: Musical positiveness conveyed by a track (range is [0, 1], where 1 is a highly positive and cheerful song).\n",
    "    - Loudness: The overall loudness of a track in decibel (dB).\n",
    "    - Tempo: The overall estimated tempo of a track in beats per minute (BPM).\n",
    "    - Acousticness: Probability whether a track is acoustic (range is [0, 1]).\n",
    "    - Energy: Perceptual measure of intensity and activity (range is [0, 1], where 1 indicates a high-energy track).\n",
    "    - Mode: Modality (major or minor) of a track, i.e., the type of scale from which its melodic content is derived. Major is 1 and minor is 0.\n",
    "    - Key: The key that the track is in. Integers map to pitches using standard Pitch Class notation.\n",
    "    - tz_Alaska_Time: Categorical - One hot encoded from (dropped) timezone column\n",
    "    - tz_Central_Time: Categorical - One hot encoded from (dropped) timezone column\n",
    "    - tz_Eastern_Time: Categorical - One hot encoded from (dropped) timezone column\n",
    "    - tz_Hawaii_Time: Categorical - One hot encoded from (dropped) timezone column\n",
    "    - tz_Mountain_Time: Categorical - One hot encoded from (dropped) timezone column\n",
    "    - tz_Pacific_Time: Categorical - One hot encoded from (dropped) timezone column\n",
    "    - sentiment: Extracted from `sentiment_score` with a range 0-1 and is the **predictor column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3r5gNwzAnCyr",
    "outputId": "1420b7e6-e5ee-4230-e32b-1345cc2547ba"
   },
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "df_mvp = df4[['sentiment','sentiment_score','user_id','track_id','time_zone','instrumentalness',\n",
    "              'liveness','speechiness','danceability','valence','loudness','tempo','acousticness','energy','mode','key']]\n",
    "df_mvp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VSLumBsSL-qw",
    "outputId": "f9e039cb-d97d-4fd9-f6c6-ab989c730079"
   },
   "outputs": [],
   "source": [
    "# Create new dataset with only user_id, track_id and time_zone and the category variables\n",
    "df_timezone = df_mvp.drop(['user_id','track_id','sentiment','sentiment_score','instrumentalness','liveness','speechiness',\n",
    "                             'danceability','valence','loudness','tempo','acousticness','energy','mode','key'], axis=1)\n",
    "df_timezone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tyGs0xtcL-qy",
    "outputId": "2755b4dd-c2a2-4c36-a9a2-003e780ee2a9"
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One Hot Encode the category data set\n",
    "one_hot_df = pd.get_dummies(df_timezone)\n",
    "one_hot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06S4qdwqL-q0",
    "outputId": "a2653321-7a01-41e9-b996-6085f0b5d05f"
   },
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "one_hot_df.columns = ['tz_Alaska_Time','tz_Central_Time','tz_Eastern_Time','tz_Hawaii_Time','tz_Mountain_Time','tz_Pacific_Time']\n",
    "one_hot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O6cGX5_VL-q4"
   },
   "outputs": [],
   "source": [
    "#Drop time_zone from MVP dataset\n",
    "df_mvp = df_mvp.drop([\"time_zone\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-l6arAXeL-q5",
    "outputId": "cfc21304-1b2d-46dc-cdf5-125ad97127cb"
   },
   "outputs": [],
   "source": [
    "#Concatenate one hot encoded dataframe\n",
    "df_mvp = pd.concat([df_mvp,one_hot_df], axis=1)\n",
    "df_mvp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qPTXwr32L-q7"
   },
   "outputs": [],
   "source": [
    "df_mvp.to_csv('module4_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QpoRdGzAnCys"
   },
   "source": [
    "## Explore the data\n",
    "\n",
    "* Look at the distribution for the data\n",
    "* Look for Multicollinearity\n",
    "* Remove unnecessary features\n",
    "* Balace and scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V0tipToWnCys",
    "outputId": "c0095126-7b3f-4a69-e9c5-68914ef2f703"
   },
   "outputs": [],
   "source": [
    "#Look at value counts of the predictor variable sentiment\n",
    "df_mvp.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9DGCrNVnCyu",
    "outputId": "d5f25c58-eba7-418f-adb0-df141903de81"
   },
   "outputs": [],
   "source": [
    "# Visualize the predictor variable\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.countplot(x='sentiment', data=df_mvp, palette='hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L_KpqcPenCyv"
   },
   "source": [
    "**Observation**: The data is very imbalanced and will need to be balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmzGqdoPnCyx",
    "outputId": "1ec8624b-30c5-454d-acd0-c400f294356c"
   },
   "outputs": [],
   "source": [
    "# Create continuous dataset and look at distributions of data\n",
    "df_mvp_lin = df_mvp.drop(['user_id','track_id','sentiment','mode','tz_Alaska_Time','tz_Central_Time','tz_Eastern_Time',\n",
    "                          'tz_Hawaii_Time','tz_Mountain_Time','tz_Pacific_Time'], axis=1)\n",
    "df_mvp_lin.hist(figsize = [30, 20]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ya7aFpBunCyy",
    "outputId": "9db1eb83-df70-4b54-8e77-981db994652b"
   },
   "outputs": [],
   "source": [
    "#Create coorelation heatmap and check for multicolinarity\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "correlation = df_mvp_lin.corr()\n",
    "plt.figure(figsize=(14, 12))\n",
    "heatmap = sns.heatmap(correlation, annot=True, linewidths=0, vmin=-1, cmap=\"RdBu_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bqq5PTIYL-rC"
   },
   "source": [
    "**Observation**: Loudness and Energy seem to be highly coorelated.\n",
    "\n",
    "## Logistic Regression\n",
    "* Normalize the data prior to fitting the model\n",
    "* Train-Test Split\n",
    "* Fit the model\n",
    "* Predict\n",
    "* Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWpAfHfKnCy1"
   },
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "y = df_mvp['sentiment']\n",
    "X = df_mvp.drop('sentiment', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UqpSwX30nCy2",
    "outputId": "c30ea908-7862-416d-cc25-7fabcb193cca"
   },
   "outputs": [],
   "source": [
    "# Normalizing the data prior to fitting the model.\n",
    "x_feats = ['sentiment_score','instrumentalness','liveness','speechiness','danceability',\n",
    "           'loudness','tempo','acousticness','energy','mode','key','valence','tz_Alaska_Time',\n",
    "           'tz_Central_Time','tz_Eastern_Time','tz_Hawaii_Time','tz_Mountain_Time','tz_Pacific_Time']\n",
    "\n",
    "X = pd.get_dummies(df_mvp[x_feats], drop_first=False)\n",
    "y = df_mvp.sentiment\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gH56DDbSnCy4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into train and test sets (automatically uses stratified sampling by labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7gWFyQ5fnCy6",
    "outputId": "91c675bc-dfa9-4b8b-95dd-44dac085ccdd"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(fit_intercept = True, C=1e12)\n",
    "model_log = logreg.fit(X_train, y_train)\n",
    "model_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdWbM-1GnCy8",
    "outputId": "09107751-70a2-4a34-ef3a-2870d8a2c136"
   },
   "outputs": [],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xcVzA9S-nCy-",
    "outputId": "b971816b-c1fd-456c-e3e3-add50e13980c"
   },
   "outputs": [],
   "source": [
    "#Predict against test set using Sigmoid function\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "y_hat_test = logreg.predict(X_test)\n",
    "y_hat_train = logreg.predict(X_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ieA_DW4dnCzA",
    "outputId": "9ccd11f3-c733-47d3-cee3-b7605e2531cc"
   },
   "outputs": [],
   "source": [
    "y_hat_test = logreg.predict_proba(X_test)\n",
    "y_hat_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJf9vWRAnCzB",
    "outputId": "441fc013-7d08-43bd-fbfd-cfc5ca48f95b"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "logreg.predict_proba(X_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UCCfZDdknCzD",
    "outputId": "a407163f-1768-4f75-8857-9b8ecc9053e0"
   },
   "outputs": [],
   "source": [
    "# How may times was the classifier correct for the training set?\n",
    "logreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vSa2mlebnCzE",
    "outputId": "3fecb6db-51c8-4564-b972-3e0d39b75b64"
   },
   "outputs": [],
   "source": [
    "# How may times was the classifier correct for the test set?\n",
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RQ0wJ7zcnCzH"
   },
   "source": [
    "### Classification Model Performance\n",
    "Check the precision, recall, and accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "seES0J89nCzI"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the precision\n",
    "def precision(y_hat, y):\n",
    "    y_y_hat = list(zip(y, y_hat))\n",
    "    tp = sum([1 for i in y_y_hat if i[0]==1 and i[1]==1])\n",
    "    fp = sum([1 for i in y_y_hat if i[0]==0 and i[1]==1])\n",
    "    return tp/float(tp+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qmih6t1UnCzJ"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the recall\n",
    "def recall(y_hat, y):\n",
    "    y_y_hat = list(zip(y, y_hat))\n",
    "    tp = sum([1 for i in y_y_hat if i[0]==1 and i[1]==1])\n",
    "    fn = sum([1 for i in y_y_hat if i[0]==1 and i[1]==0])\n",
    "    return tp/float(tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRBvVmWHnCzL"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy\n",
    "def accuracy(y_hat, y):\n",
    "    y_y_hat = list(zip(y, y_hat))\n",
    "    tp = sum([1 for i in y_y_hat if i[0]==1 and i[1]==1])\n",
    "    tn = sum([1 for i in y_y_hat if i[0]==0 and i[1]==0])\n",
    "    return (tp+tn)/float(len(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWDJR3QvnCzM",
    "outputId": "748fcc83-37a1-4cc6-e4b6-7c1dde09c45c"
   },
   "outputs": [],
   "source": [
    "# Calculate the precision, recall and accuracy of the classifier.\n",
    "y_hat_test = logreg.predict(X_test)\n",
    "y_hat_train = logreg.predict(X_train)\n",
    "\n",
    "print('Training Precision: ', precision(y_hat_train, y_train))\n",
    "print('Testing Precision: ', precision(y_hat_test, y_test))\n",
    "print('\\n')\n",
    "\n",
    "print('Training Recall: ', recall(y_hat_train, y_train))\n",
    "print('Testing Recall: ', recall(y_hat_test, y_test))\n",
    "print('\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy(y_hat_train, y_train))\n",
    "print('Testing Accuracy: ', accuracy(y_hat_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qIHfSd-7L-rZ"
   },
   "source": [
    "### Resample data since it's imbalanced and all scores are very high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0kKDl_mNL-rZ"
   },
   "outputs": [],
   "source": [
    "# concatenate our training data back together\n",
    "training_data = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0M4sff1L-rc"
   },
   "outputs": [],
   "source": [
    "# separate minority and majority classes\n",
    "not_safe = training_data[training_data.sentiment==0]\n",
    "safe = training_data[training_data.sentiment==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DAm6830OL-rd"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "# upsample minority\n",
    "not_safe_upsampled = resample(not_safe, \n",
    "                              replace=True, # sample with replacement\n",
    "                              n_samples=len(safe), # match number in majority class\n",
    "                              random_state=42) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q5-b-LPvL-re"
   },
   "outputs": [],
   "source": [
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([safe, not_safe_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7w9lU4-cL-rf",
    "outputId": "195ccbee-1780-4b79-d5b8-a0f47ed5c29e"
   },
   "outputs": [],
   "source": [
    "# check new class counts\n",
    "print(upsampled.sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tBm1_QASL-rg",
    "outputId": "850c4f21-817d-4649-c35b-425a345e6a73"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='sentiment', data=upsampled, palette='hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rfhOs9odL-rh"
   },
   "outputs": [],
   "source": [
    "X_train = upsampled.drop('sentiment', axis=1)\n",
    "y_train = upsampled.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NPXnzbNdL-ri",
    "outputId": "5ed26ac0-678c-4b1a-f304-b291a7a48d23"
   },
   "outputs": [],
   "source": [
    "# Scaling X using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Only fit training data to avoid data leakage\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=list(X.columns))\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=list(X.columns))\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2-XMD3PhL-rk"
   },
   "source": [
    "### Run another Logistic Regression Model with resampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rurlNgwfL-rl",
    "outputId": "c120d21f-aac5-476a-ee3b-83e1e132af0f"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logreg2 = LogisticRegression(fit_intercept = True, C=1e12)\n",
    "model_log = logreg2.fit(X_train, y_train)\n",
    "model_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kjt7gxvvL-rm",
    "outputId": "62e567d8-400f-4da3-c358-0257573876b5"
   },
   "outputs": [],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v2k_VnuYL-rn",
    "outputId": "bcc40020-8b47-4491-dcc2-0f72742a16e2"
   },
   "outputs": [],
   "source": [
    "# Predict against test set using Sigmoid function\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "y_hat_test = logreg2.predict(X_test)\n",
    "y_hat_train = logreg2.predict(X_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UQMYhYD2L-rq",
    "outputId": "9cb9f626-6156-4b47-fef4-a6284bcac0c8"
   },
   "outputs": [],
   "source": [
    "y_hat_test = logreg2.predict_proba(X_test)\n",
    "y_hat_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rkEJh4BHL-rs",
    "outputId": "904d15fc-206c-45d0-8381-3d065ddb7b2f"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "logreg2.predict_proba(X_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-GyiDTRL-rt",
    "outputId": "2a1d3af2-5189-4b87-f794-8b89c69e7fb3"
   },
   "outputs": [],
   "source": [
    "#Train score\n",
    "logreg2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOvY9wVhL-ru",
    "outputId": "4d2b6cda-1be4-4175-a57b-34ba80758bc6"
   },
   "outputs": [],
   "source": [
    "#Test score\n",
    "logreg2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qco4ty7JL-rv",
    "outputId": "9a30ae99-f8bd-4dca-fd39-e767d28d47a1"
   },
   "outputs": [],
   "source": [
    "logreg2.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qKqQLa-7L-rw",
    "outputId": "30245a51-f658-4d50-e867-f2d64ec345dc"
   },
   "outputs": [],
   "source": [
    "for feature, weight in zip(X.columns, logreg2.coef_[0]):\n",
    "    print(\"{} has a weight of : {}\".format(feature, weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oRCDiuQ3L-rx"
   },
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Show the performance of the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eD1q5z4WnCzO",
    "outputId": "9ef7e6d0-33af-49b1-e763-d6e1a017a87d"
   },
   "outputs": [],
   "source": [
    "#Create a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_train, y_hat_train)\n",
    "print('Confusion Matrix:\\n',cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jbq8Mk-3nCzP",
    "outputId": "a071d458-c663-4c23-c88e-06d2273166f6"
   },
   "outputs": [],
   "source": [
    "#Plot the Confusion Matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(cnf_matrix,  cmap=plt.cm.Blues) #Create the basic matrix\n",
    "\n",
    "#Add title and axis labels\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "#Add appropriate axis scales\n",
    "class_names = set(y) #Get class labels to add to matrix\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names, rotation=45)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "#Add Labels to each cell\n",
    "thresh = cnf_matrix.max() / 2. #Used for text coloring below\n",
    "#Here we iterate through the confusion matrix and append labels to our visualization\n",
    "for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "        plt.text(j, i, cnf_matrix[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "#Add a side bar legend showing colors\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSF1Of5cqQBA"
   },
   "outputs": [],
   "source": [
    "#conf_matrix function\n",
    "def conf_matrix(y_true, y_pred):\n",
    "    cm = {'TP': 0, 'TN': 0, 'FP': 0, 'FN': 0}\n",
    "    \n",
    "    for ind, label in enumerate(y_true):\n",
    "        pred = y_pred[ind]\n",
    "        if label == 1:\n",
    "            # CASE: TP \n",
    "            if label == pred:\n",
    "                cm['TP'] += 1\n",
    "            # CASE: FN\n",
    "            else:\n",
    "                cm['FN'] += 1\n",
    "        else:\n",
    "            # CASE: TN\n",
    "            if label == pred:\n",
    "                cm['TN'] += 1\n",
    "            # CASE: FP\n",
    "            else:\n",
    "                cm['FP'] += 1\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5UhiwmR2qQBB"
   },
   "outputs": [],
   "source": [
    "#Set variable\n",
    "model_confusion_matrix = conf_matrix(y_train, y_hat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jKn47vpsqQBC"
   },
   "outputs": [],
   "source": [
    "#Precision function\n",
    "def precision(confusion_matrix):\n",
    "    return confusion_matrix['TP'] / (confusion_matrix['TP'] + confusion_matrix['FP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CNDVnr-DqQBE"
   },
   "outputs": [],
   "source": [
    "#Recall function\n",
    "def recall(confusion_matrix):\n",
    "    return confusion_matrix['TP'] / (confusion_matrix['TP'] + confusion_matrix['FN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EAQsqqeRqQBE"
   },
   "outputs": [],
   "source": [
    "#Accuracy function\n",
    "def accuracy(confusion_matrix):\n",
    "    return (confusion_matrix['TP'] + confusion_matrix['TN']) / sum(confusion_matrix.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H1WG2r8PqQBF"
   },
   "outputs": [],
   "source": [
    "#f1 score\n",
    "def f1(confusion_matrix):\n",
    "    precision_score = precision(confusion_matrix)\n",
    "    recall_score = recall(confusion_matrix)\n",
    "    numerator = precision_score * recall_score\n",
    "    denominator = precision_score + recall_score\n",
    "    return 2 * (numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hMyoP-zGqQBG",
    "outputId": "e08479b9-b237-4d6e-8c10-96ff9be4ab60"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "preds = [y_hat_train]\n",
    "\n",
    "for ind, i in enumerate(preds):\n",
    "    print('-'*40)\n",
    "    print('Model Metrics:'.format(ind + 1))\n",
    "    print('Precision: {}'.format(precision_score(y_train, i)))\n",
    "    print('Recall: {}'.format(recall_score(y_train, i)))\n",
    "    print('Accuracy: {}'.format(accuracy_score(y_train, i)))\n",
    "    print('F1-Score: {}'.format(f1_score(y_train, i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxIYhMSGqQBH",
    "outputId": "98254056-ada4-4891-91f2-0510d809c935"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for ind, i in enumerate(preds):\n",
    "    print('-'*40)\n",
    "    print(\"Model Classification Report:\".format(ind + 1))\n",
    "    print(classification_report(y_train, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J4IXrteDMtsd"
   },
   "source": [
    "## Cross Validation\n",
    "Repeat a train-test-split creation 20 times, using a test_size of 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PEsy9nkWqQBJ",
    "outputId": "d21b6bb4-182a-4b07-d739-8ba0907ddf7b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num = 20\n",
    "train_err = []\n",
    "test_err = []\n",
    "for i in range(num):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
    "    logreg2.fit(X_train, y_train)\n",
    "    y_hat_train = logreg2.predict(X_train)\n",
    "    y_hat_test = logreg2.predict(X_test)\n",
    "    train_err.append(mean_squared_error(y_train, y_hat_train))\n",
    "    test_err.append(mean_squared_error(y_test, y_hat_test))\n",
    "plt.scatter(list(range(num)), train_err, label='Training Error')\n",
    "plt.scatter(list(range(num)), test_err, label='Testing Error')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J_P8W2mSqQBK",
    "outputId": "0c9b8a71-16da-4e82-ebb9-92ddd58ad83c"
   },
   "outputs": [],
   "source": [
    "#K-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_5_results = np.mean(cross_val_score(logreg2, X, y, cv=5, scoring=\"accuracy\"))\n",
    "cv_10_results = np.mean(cross_val_score(logreg2, X, y, cv=10, scoring=\"accuracy\"))\n",
    "cv_20_results = np.mean(cross_val_score(logreg2, X, y, cv=20, scoring=\"accuracy\"))\n",
    "\n",
    "print(cv_5_results)\n",
    "print(cv_10_results)\n",
    "print(cv_20_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8FTNEySL-r1"
   },
   "source": [
    "## Create a Sequential Neural Network\n",
    "- ReLU activation function\n",
    "- Sigmoid function on the output layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWR8x3d1L-r3",
    "outputId": "8604551e-a247-4b56-985d-14e88656abc8"
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# split into input (X) and output (y) variables\n",
    "X = pd.get_dummies(df_mvp[x_feats], drop_first=False)\n",
    "y = df_mvp.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0OR6gL5nCzS"
   },
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=18, activation='relu'))\n",
    "model.add(Dense(19, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U3RBwALtL-r6"
   },
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KHBHfbT2L-r7"
   },
   "outputs": [],
   "source": [
    "# Set callback functions to early stop training and save the best model so far\n",
    "checkpoint = [ModelCheckpoint(filepath='models.hdf5', save_best_only=True, monitor='val_loss')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvBhhejgL-r9",
    "outputId": "ce0eadca-c9e3-4e93-a575-366a329366df"
   },
   "outputs": [],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=10, callbacks=checkpoint, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kvf2AxWWL-sA",
    "outputId": "fc87557a-8182-467f-d1d5-5d341ccd8674"
   },
   "outputs": [],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VsTAEuRbqQBT"
   },
   "source": [
    "## Create a Sequential Neural Network with the scaled data\n",
    "- ReLU activation function\n",
    "- Sigmoid function on the output layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ojIfMtATqQBU"
   },
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X = pd.get_dummies(X_train, drop_first=False) #X_train = upsampled.drop('sentiment', axis=1)\n",
    "y = y_train #y_train = upsampled.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3n7DM1OWqQBV"
   },
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(12, input_dim=18, activation='relu'))\n",
    "model2.add(Dense(8, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "scXb6rOcqQBW"
   },
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9pyOTHAfqQBX"
   },
   "outputs": [],
   "source": [
    "# Set callback functions to early stop training and save the best model so far\n",
    "checkpoint = [ModelCheckpoint(filepath='models.hdf5', save_best_only=True, monitor='val_loss')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FdWpHr0qQBY",
    "outputId": "964ca7c1-fd50-4696-9053-6c03d75c7203"
   },
   "outputs": [],
   "source": [
    "# fit the keras model on the dataset\n",
    "model2.fit(X, y, epochs=10, callbacks=checkpoint, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Na0fLdDgqQBZ",
    "outputId": "e1b30fbd-76f1-476f-da97-a7ee6b43dfd6"
   },
   "outputs": [],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model2.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Uytuuf9unCyG",
    "GDvHzkARnCyU"
   ],
   "name": "student.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
