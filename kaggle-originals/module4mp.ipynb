{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "ur2KW1sdnCxW",
    "outputId": "f584d998-ff68-4aea-8b52-f2159fc35774"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import helppd2sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "eeqIIUuhnCxd",
    "outputId": "3eb50f87-f84a-4400-a6c0-d1e6843a504b"
   },
   "outputs": [],
   "source": [
    "sentiment_values = pd.read_csv('../data/chelseapower/fixed_sentiment_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_sent = sentiment_values[['hashtag', 'ol_score', 'ol_avg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proj_sent.apply(lambda x: x.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8q4SwdsLnCx0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-03a699e8aca2>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  proj_sent['ol_score'] = proj_sent['ol_score'].combine_first(\n"
     ]
    }
   ],
   "source": [
    "# COALESCE (ol_score, ol_avg) NOT SUPPORTED YET\n",
    "proj_sent['ol_score'] = proj_sent['ol_score'].combine_first(\n",
    "    proj_sent['ol_avg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proj_sent.apply(lambda x: x.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y362R5B-nCx9",
    "outputId": "746c3f05-f5b3-475d-bab4-0adebee8e91c"
   },
   "outputs": [],
   "source": [
    "# UNREACHABLE\n",
    "dropna_sentiments = proj_sent.dropna(axis = 0, how ='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q9HBSRRunCyC",
    "outputId": "6c1ef443-a03f-4c82-94a2-7228ca8366b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\ssdapps\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py:4441: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().rename(\n"
     ]
    }
   ],
   "source": [
    "# UNREACHABLE\n",
    "dropna_sentiments.rename(columns = {'ol_score':'sentiment_score'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sdPozOhonCyG",
    "outputId": "02c3c306-4ac6-4771-8eb9-2031f306f66b"
   },
   "outputs": [],
   "source": [
    "user_track = pd.read_csv('../data/chelseapower/user_track_hashtag_timestamp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AMx_kUxdnCyL",
    "outputId": "0c7f0981-a89e-4cd3-ccaf-e56061441368",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# explorative analysis - comment out for benchmark\n",
    "# df2.apply(lambda x: x.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kPBEsdKsnCyN",
    "outputId": "356171d9-98d2-402d-b1fc-ab3869999e40"
   },
   "outputs": [],
   "source": [
    "dropna_user = user_track.dropna(subset=['hashtag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q2haAh95nCyO",
    "outputId": "51a2c4f8-0f17-493c-fcc3-7a567453bef4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "counts = dropna_user['track_id'].value_counts()\n",
    "popular = counts[counts >= 50]\n",
    "pop_user_list = popular.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_user = dropna_user[dropna_user['track_id'].\n",
    "                                       isin(pop_user_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9fqAkHqSnCyV",
    "outputId": "15bff8d1-b657-4d01-c158-1ea141c050f6"
   },
   "outputs": [],
   "source": [
    "context_content_features = pd.read_csv(\n",
    "    '../data/chelseapower/fixed_context_content_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_8k9ejUnCyW",
    "outputId": "d1f6bb99-c073-4ed9-e626-f61ddfbd8908"
   },
   "outputs": [],
   "source": [
    "counts3 = context_content_features['track_id'].value_counts()\n",
    "popular3 = counts3[counts3 >= 50]\n",
    "pop_context_index = popular3.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11614671\n",
      "37447\n",
      "346700\n"
     ]
    }
   ],
   "source": [
    "print(len(context_content_features))\n",
    "print(len(pop_context_list))\n",
    "print(len(counts3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_context = context_content_features[context_content_features['track_id'].\n",
    "                                       isin(pop_context_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9143294"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pop_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set(pop_context.columns) - {'coordinates','id',\n",
    "#    'place','geo', 'created_at','artist_id','tweet_lang'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hWrWRfRmnCyZ",
    "outputId": "ac25279a-5d55-4218-ac6f-4f592dade846"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"instrumentalness\", \"liveness\", \"speechiness\", \"danceability\", \"valence\", \"loudness\", \"tempo\", \"acousticness\", \"energy\", \"mode\", \"key\", \"track_id\", \"created_at\", \"lang\", \"time_zone\", \"user_id\"'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj_context = pop_context.drop(\n",
    "    columns=['coordinates','id','place','geo','artist_id','tweet_lang'])\n",
    "helppd2sql.drop2select(proj_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proj_context.apply(lambda x: x.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T2Bqn9lknCyb",
    "outputId": "8cd3393e-6220-46e4-983f-a6aed4f2992f"
   },
   "outputs": [],
   "source": [
    "dropna_context = proj_context.dropna(subset=\n",
    "                 ['instrumentalness', 'liveness', 'speechiness',\n",
    "                  'danceability', 'valence', 'acousticness',\n",
    "                  'energy', 'mode', 'key', 'time_zone', 'user_id'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CoKqjx6DnCyc"
   },
   "source": [
    "Reduced the dataset from 10,887,911 to **6,413,576** by dropping all null value rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3TK6Agf8nCyd",
    "outputId": "69772bcb-adb1-4e74-ded7-38529fc7f7fc"
   },
   "outputs": [],
   "source": [
    "english_context = dropna_context[dropna_context['lang'] == 'en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nA67Gv09L-qo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"instrumentalness\", \"liveness\", \"speechiness\", \"danceability\", \"valence\", \"loudness\", \"tempo\", \"acousticness\", \"energy\", \"mode\", \"key\", \"track_id\", \"created_at\", \"time_zone\", \"user_id\"'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CTE rename_context\n",
    "english_context = english_context.drop(columns=['lang'])\n",
    "english_context['time_zone'].replace('Eastern Time (US & Canada)', 'Eastern Time', inplace=True)\n",
    "english_context['time_zone'].replace('Central Time (US & Canada)', 'Central Time', inplace=True)\n",
    "english_context['time_zone'].replace('Pacific Time (US & Canada)', 'Pacific Time', inplace=True)\n",
    "english_context['time_zone'].replace('Mountain Time (US & Canada)', 'Mountain Time', inplace=True)\n",
    "english_context['time_zone'].replace('Alaska', 'Alaska Time', inplace=True)\n",
    "english_context['time_zone'].replace('Hawaii', 'Hawaii Time', inplace=True)\n",
    "english_context['time_zone'].replace('Arizona', 'Mountain Time', inplace=True)\n",
    "english_context['time_zone'].replace('America/Chicago', 'Central Time', inplace=True)\n",
    "english_context['time_zone'].replace('America/New_York', 'Eastern Time', inplace=True)\n",
    "english_context['time_zone'].replace('America/Los_Angeles', 'Pacific Time', inplace=True)\n",
    "english_context['time_zone'].replace('America/Denver', 'Mountain Time', inplace=True)\n",
    "english_context['time_zone'].replace('America/Detroit', 'Eastern Time', inplace=True)\n",
    "helppd2sql.drop2select(english_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c3QrUdhAL-qq",
    "outputId": "cb3f5347-c113-4dfc-89ed-a94862ca3d38"
   },
   "outputs": [],
   "source": [
    "usa_context = english_context[english_context['time_zone'].isin(\n",
    "    ['Eastern Time', 'Central Time', 'Pacific Time',\n",
    "     'Mountain Time', 'Alaska Time', 'Hawaii Time'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PzXj5dnwnCyh",
    "outputId": "5f460884-8c14-4a19-9d1c-21586522c9b9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df23 = usa_context.merge(\n",
    "    pop_user, on=['track_id','created_at','user_id'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"instrumentalness\", \"liveness\", \"speechiness\", \"danceability\", \"valence\", \"loudness\", \"tempo\", \"acousticness\", \"energy\", \"mode\", \"key\", \"track_id\", \"time_zone\", \"user_id\", \"hashtag\"'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df23_drop = df23.drop(columns=['created_at'])\n",
    "helppd2sql.drop2select(df23_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsupported because df1 is in Python\n",
    "df123 = dropna_sentiments.merge(df23, on=['hashtag'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsupported because df123 is in Python\n",
    "df123 = df123.drop(columns=['hashtag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vIU8HApJnCyj",
    "outputId": "71d93ddc-b420-4a36-c067-029afb791c88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 69428 entries, 0 to 69427\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   hashtag           69428 non-null  object \n",
      " 1   sentiment_score   69428 non-null  float64\n",
      " 2   ol_avg            69428 non-null  float64\n",
      " 3   user_id           69428 non-null  object \n",
      " 4   track_id          69428 non-null  object \n",
      " 5   created_at        69428 non-null  object \n",
      " 6   instrumentalness  69428 non-null  float64\n",
      " 7   liveness          69428 non-null  float64\n",
      " 8   speechiness       69428 non-null  float64\n",
      " 9   danceability      69428 non-null  float64\n",
      " 10  valence           69428 non-null  float64\n",
      " 11  loudness          69428 non-null  float64\n",
      " 12  tempo             69428 non-null  float64\n",
      " 13  acousticness      69428 non-null  float64\n",
      " 14  energy            69428 non-null  float64\n",
      " 15  mode              69428 non-null  Int64  \n",
      " 16  key               69428 non-null  float64\n",
      " 17  artist_id         69428 non-null  object \n",
      " 18  tweet_lang        69428 non-null  object \n",
      " 19  lang              69428 non-null  object \n",
      " 20  time_zone         69428 non-null  object \n",
      "dtypes: Int64(1), float64(12), object(8)\n",
      "memory usage: 11.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Unsupported\n",
    "df123['mode'] = df123['mode'].astype('Int64')\n",
    "df123['user_id'] = df123['user_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cMA4BSFanCyl",
    "outputId": "1267dc19-42ba-49f8-db35-482d60288966"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hashtag            0\n",
       "sentiment_score    0\n",
       "ol_avg             0\n",
       "user_id            0\n",
       "track_id           0\n",
       "created_at         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create new column sentiment that will be the predictor based on the sentiment_score values\n",
    "df123['sentiment'] = np.where(df123['sentiment_score']>= 0.01, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3r5gNwzAnCyr",
    "outputId": "1420b7e6-e5ee-4230-e32b-1345cc2547ba"
   },
   "outputs": [],
   "source": [
    "# Reorder columns\n",
    "df_mvp = df123[['sentiment','sentiment_score','user_id','track_id','time_zone','instrumentalness',\n",
    "              'liveness','speechiness','danceability','valence','loudness','tempo','acousticness','energy','mode','key']]\n",
    "df_mvp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = helppd2sql.global_report()\n",
    "report_df = pandas.DataFrame(report)\n",
    "report_df('pandas_report.csv', index=False)\n",
    "exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VSLumBsSL-qw",
    "outputId": "f9e039cb-d97d-4fd9-f6c6-ab989c730079"
   },
   "outputs": [],
   "source": [
    "# Create new dataset with only user_id, track_id and time_zone and the category variables\n",
    "df_timezone = df_mvp.drop(['user_id','track_id','sentiment','sentiment_score','instrumentalness','liveness','speechiness',\n",
    "                             'danceability','valence','loudness','tempo','acousticness','energy','mode','key'], axis=1)\n",
    "df_timezone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tyGs0xtcL-qy",
    "outputId": "2755b4dd-c2a2-4c36-a9a2-003e780ee2a9"
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One Hot Encode the category data set\n",
    "one_hot_df = pd.get_dummies(df_timezone)\n",
    "one_hot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "06S4qdwqL-q0",
    "outputId": "a2653321-7a01-41e9-b996-6085f0b5d05f"
   },
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "one_hot_df.columns = ['tz_Alaska_Time','tz_Central_Time','tz_Eastern_Time','tz_Hawaii_Time','tz_Mountain_Time','tz_Pacific_Time']\n",
    "one_hot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O6cGX5_VL-q4"
   },
   "outputs": [],
   "source": [
    "#Drop time_zone from MVP dataset\n",
    "df_mvp = df_mvp.drop([\"time_zone\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-l6arAXeL-q5",
    "outputId": "cfc21304-1b2d-46dc-cdf5-125ad97127cb"
   },
   "outputs": [],
   "source": [
    "#Concatenate one hot encoded dataframe\n",
    "df_mvp = pd.concat([df_mvp,one_hot_df], axis=1)\n",
    "df_mvp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qPTXwr32L-q7"
   },
   "outputs": [],
   "source": [
    "df_mvp.to_csv('module4_cleaned.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QpoRdGzAnCys"
   },
   "source": [
    "## Explore the data\n",
    "\n",
    "* Look at the distribution for the data\n",
    "* Look for Multicollinearity\n",
    "* Remove unnecessary features\n",
    "* Balace and scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V0tipToWnCys",
    "outputId": "c0095126-7b3f-4a69-e9c5-68914ef2f703"
   },
   "outputs": [],
   "source": [
    "#Look at value counts of the predictor variable sentiment\n",
    "df_mvp.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s9DGCrNVnCyu",
    "outputId": "d5f25c58-eba7-418f-adb0-df141903de81"
   },
   "outputs": [],
   "source": [
    "# Visualize the predictor variable\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.countplot(x='sentiment', data=df_mvp, palette='hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L_KpqcPenCyv"
   },
   "source": [
    "**Observation**: The data is very imbalanced and will need to be balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmzGqdoPnCyx",
    "outputId": "1ec8624b-30c5-454d-acd0-c400f294356c"
   },
   "outputs": [],
   "source": [
    "# Create continuous dataset and look at distributions of data\n",
    "df_mvp_lin = df_mvp.drop(['user_id','track_id','sentiment','mode','tz_Alaska_Time','tz_Central_Time','tz_Eastern_Time',\n",
    "                          'tz_Hawaii_Time','tz_Mountain_Time','tz_Pacific_Time'], axis=1)\n",
    "df_mvp_lin.hist(figsize = [30, 20]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ya7aFpBunCyy",
    "outputId": "9db1eb83-df70-4b54-8e77-981db994652b"
   },
   "outputs": [],
   "source": [
    "#Create coorelation heatmap and check for multicolinarity\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "correlation = df_mvp_lin.corr()\n",
    "plt.figure(figsize=(14, 12))\n",
    "heatmap = sns.heatmap(correlation, annot=True, linewidths=0, vmin=-1, cmap=\"RdBu_r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bqq5PTIYL-rC"
   },
   "source": [
    "**Observation**: Loudness and Energy seem to be highly coorelated.\n",
    "\n",
    "## Logistic Regression\n",
    "* Normalize the data prior to fitting the model\n",
    "* Train-Test Split\n",
    "* Fit the model\n",
    "* Predict\n",
    "* Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWpAfHfKnCy1"
   },
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "y = df_mvp['sentiment']\n",
    "X = df_mvp.drop('sentiment', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UqpSwX30nCy2",
    "outputId": "c30ea908-7862-416d-cc25-7fabcb193cca"
   },
   "outputs": [],
   "source": [
    "# Normalizing the data prior to fitting the model.\n",
    "x_feats = ['sentiment_score','instrumentalness','liveness','speechiness','danceability',\n",
    "           'loudness','tempo','acousticness','energy','mode','key','valence','tz_Alaska_Time',\n",
    "           'tz_Central_Time','tz_Eastern_Time','tz_Hawaii_Time','tz_Mountain_Time','tz_Pacific_Time']\n",
    "\n",
    "X = pd.get_dummies(df_mvp[x_feats], drop_first=False)\n",
    "y = df_mvp.sentiment\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gH56DDbSnCy4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into train and test sets (automatically uses stratified sampling by labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7gWFyQ5fnCy6",
    "outputId": "91c675bc-dfa9-4b8b-95dd-44dac085ccdd"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(fit_intercept = True, C=1e12)\n",
    "model_log = logreg.fit(X_train, y_train)\n",
    "model_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdWbM-1GnCy8",
    "outputId": "09107751-70a2-4a34-ef3a-2870d8a2c136"
   },
   "outputs": [],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xcVzA9S-nCy-",
    "outputId": "b971816b-c1fd-456c-e3e3-add50e13980c"
   },
   "outputs": [],
   "source": [
    "#Predict against test set using Sigmoid function\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "y_hat_test = logreg.predict(X_test)\n",
    "y_hat_train = logreg.predict(X_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ieA_DW4dnCzA",
    "outputId": "9ccd11f3-c733-47d3-cee3-b7605e2531cc"
   },
   "outputs": [],
   "source": [
    "y_hat_test = logreg.predict_proba(X_test)\n",
    "y_hat_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJf9vWRAnCzB",
    "outputId": "441fc013-7d08-43bd-fbfd-cfc5ca48f95b"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "logreg.predict_proba(X_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UCCfZDdknCzD",
    "outputId": "a407163f-1768-4f75-8857-9b8ecc9053e0"
   },
   "outputs": [],
   "source": [
    "# How may times was the classifier correct for the training set?\n",
    "logreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vSa2mlebnCzE",
    "outputId": "3fecb6db-51c8-4564-b972-3e0d39b75b64"
   },
   "outputs": [],
   "source": [
    "# How may times was the classifier correct for the test set?\n",
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RQ0wJ7zcnCzH"
   },
   "source": [
    "### Classification Model Performance\n",
    "Check the precision, recall, and accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "seES0J89nCzI"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the precision\n",
    "def precision(y_hat, y):\n",
    "    y_y_hat = list(zip(y, y_hat))\n",
    "    tp = sum([1 for i in y_y_hat if i[0]==1 and i[1]==1])\n",
    "    fp = sum([1 for i in y_y_hat if i[0]==0 and i[1]==1])\n",
    "    return tp/float(tp+fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qmih6t1UnCzJ"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the recall\n",
    "def recall(y_hat, y):\n",
    "    y_y_hat = list(zip(y, y_hat))\n",
    "    tp = sum([1 for i in y_y_hat if i[0]==1 and i[1]==1])\n",
    "    fn = sum([1 for i in y_y_hat if i[0]==1 and i[1]==0])\n",
    "    return tp/float(tp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bRBvVmWHnCzL"
   },
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy\n",
    "def accuracy(y_hat, y):\n",
    "    y_y_hat = list(zip(y, y_hat))\n",
    "    tp = sum([1 for i in y_y_hat if i[0]==1 and i[1]==1])\n",
    "    tn = sum([1 for i in y_y_hat if i[0]==0 and i[1]==0])\n",
    "    return (tp+tn)/float(len(y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MWDJR3QvnCzM",
    "outputId": "748fcc83-37a1-4cc6-e4b6-7c1dde09c45c"
   },
   "outputs": [],
   "source": [
    "# Calculate the precision, recall and accuracy of the classifier.\n",
    "y_hat_test = logreg.predict(X_test)\n",
    "y_hat_train = logreg.predict(X_train)\n",
    "\n",
    "print('Training Precision: ', precision(y_hat_train, y_train))\n",
    "print('Testing Precision: ', precision(y_hat_test, y_test))\n",
    "print('\\n')\n",
    "\n",
    "print('Training Recall: ', recall(y_hat_train, y_train))\n",
    "print('Testing Recall: ', recall(y_hat_test, y_test))\n",
    "print('\\n')\n",
    "\n",
    "print('Training Accuracy: ', accuracy(y_hat_train, y_train))\n",
    "print('Testing Accuracy: ', accuracy(y_hat_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qIHfSd-7L-rZ"
   },
   "source": [
    "### Resample data since it's imbalanced and all scores are very high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0kKDl_mNL-rZ"
   },
   "outputs": [],
   "source": [
    "# concatenate our training data back together\n",
    "training_data = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j0M4sff1L-rc"
   },
   "outputs": [],
   "source": [
    "# separate minority and majority classes\n",
    "not_safe = training_data[training_data.sentiment==0]\n",
    "safe = training_data[training_data.sentiment==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DAm6830OL-rd"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "# upsample minority\n",
    "not_safe_upsampled = resample(not_safe, \n",
    "                              replace=True, # sample with replacement\n",
    "                              n_samples=len(safe), # match number in majority class\n",
    "                              random_state=42) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q5-b-LPvL-re"
   },
   "outputs": [],
   "source": [
    "# combine majority and upsampled minority\n",
    "upsampled = pd.concat([safe, not_safe_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7w9lU4-cL-rf",
    "outputId": "195ccbee-1780-4b79-d5b8-a0f47ed5c29e"
   },
   "outputs": [],
   "source": [
    "# check new class counts\n",
    "print(upsampled.sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tBm1_QASL-rg",
    "outputId": "850c4f21-817d-4649-c35b-425a345e6a73"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='sentiment', data=upsampled, palette='hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rfhOs9odL-rh"
   },
   "outputs": [],
   "source": [
    "X_train = upsampled.drop('sentiment', axis=1)\n",
    "y_train = upsampled.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NPXnzbNdL-ri",
    "outputId": "5ed26ac0-678c-4b1a-f304-b291a7a48d23"
   },
   "outputs": [],
   "source": [
    "# Scaling X using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Only fit training data to avoid data leakage\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=list(X.columns))\n",
    "X_test = pd.DataFrame(scaler.transform(X_test), columns=list(X.columns))\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2-XMD3PhL-rk"
   },
   "source": [
    "### Run another Logistic Regression Model with resampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rurlNgwfL-rl",
    "outputId": "c120d21f-aac5-476a-ee3b-83e1e132af0f"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "logreg2 = LogisticRegression(fit_intercept = True, C=1e12)\n",
    "model_log = logreg2.fit(X_train, y_train)\n",
    "model_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kjt7gxvvL-rm",
    "outputId": "62e567d8-400f-4da3-c358-0257573876b5"
   },
   "outputs": [],
   "source": [
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v2k_VnuYL-rn",
    "outputId": "bcc40020-8b47-4491-dcc2-0f72742a16e2"
   },
   "outputs": [],
   "source": [
    "# Predict against test set using Sigmoid function\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "y_hat_test = logreg2.predict(X_test)\n",
    "y_hat_train = logreg2.predict(X_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UQMYhYD2L-rq",
    "outputId": "9cb9f626-6156-4b47-fef4-a6284bcac0c8"
   },
   "outputs": [],
   "source": [
    "y_hat_test = logreg2.predict_proba(X_test)\n",
    "y_hat_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rkEJh4BHL-rs",
    "outputId": "904d15fc-206c-45d0-8381-3d065ddb7b2f"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "logreg2.predict_proba(X_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Execution time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-GyiDTRL-rt",
    "outputId": "2a1d3af2-5189-4b87-f794-8b89c69e7fb3"
   },
   "outputs": [],
   "source": [
    "#Train score\n",
    "logreg2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOvY9wVhL-ru",
    "outputId": "4d2b6cda-1be4-4175-a57b-34ba80758bc6"
   },
   "outputs": [],
   "source": [
    "#Test score\n",
    "logreg2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qco4ty7JL-rv",
    "outputId": "9a30ae99-f8bd-4dca-fd39-e767d28d47a1"
   },
   "outputs": [],
   "source": [
    "logreg2.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qKqQLa-7L-rw",
    "outputId": "30245a51-f658-4d50-e867-f2d64ec345dc"
   },
   "outputs": [],
   "source": [
    "for feature, weight in zip(X.columns, logreg2.coef_[0]):\n",
    "    print(\"{} has a weight of : {}\".format(feature, weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oRCDiuQ3L-rx"
   },
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Show the performance of the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eD1q5z4WnCzO",
    "outputId": "9ef7e6d0-33af-49b1-e763-d6e1a017a87d"
   },
   "outputs": [],
   "source": [
    "#Create a Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_train, y_hat_train)\n",
    "print('Confusion Matrix:\\n',cnf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jbq8Mk-3nCzP",
    "outputId": "a071d458-c663-4c23-c88e-06d2273166f6"
   },
   "outputs": [],
   "source": [
    "#Plot the Confusion Matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.imshow(cnf_matrix,  cmap=plt.cm.Blues) #Create the basic matrix\n",
    "\n",
    "#Add title and axis labels\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "#Add appropriate axis scales\n",
    "class_names = set(y) #Get class labels to add to matrix\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names, rotation=45)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "#Add Labels to each cell\n",
    "thresh = cnf_matrix.max() / 2. #Used for text coloring below\n",
    "#Here we iterate through the confusion matrix and append labels to our visualization\n",
    "for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "        plt.text(j, i, cnf_matrix[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "#Add a side bar legend showing colors\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSF1Of5cqQBA"
   },
   "outputs": [],
   "source": [
    "#conf_matrix function\n",
    "def conf_matrix(y_true, y_pred):\n",
    "    cm = {'TP': 0, 'TN': 0, 'FP': 0, 'FN': 0}\n",
    "    \n",
    "    for ind, label in enumerate(y_true):\n",
    "        pred = y_pred[ind]\n",
    "        if label == 1:\n",
    "            # CASE: TP \n",
    "            if label == pred:\n",
    "                cm['TP'] += 1\n",
    "            # CASE: FN\n",
    "            else:\n",
    "                cm['FN'] += 1\n",
    "        else:\n",
    "            # CASE: TN\n",
    "            if label == pred:\n",
    "                cm['TN'] += 1\n",
    "            # CASE: FP\n",
    "            else:\n",
    "                cm['FP'] += 1\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5UhiwmR2qQBB"
   },
   "outputs": [],
   "source": [
    "#Set variable\n",
    "model_confusion_matrix = conf_matrix(y_train, y_hat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jKn47vpsqQBC"
   },
   "outputs": [],
   "source": [
    "#Precision function\n",
    "def precision(confusion_matrix):\n",
    "    return confusion_matrix['TP'] / (confusion_matrix['TP'] + confusion_matrix['FP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CNDVnr-DqQBE"
   },
   "outputs": [],
   "source": [
    "#Recall function\n",
    "def recall(confusion_matrix):\n",
    "    return confusion_matrix['TP'] / (confusion_matrix['TP'] + confusion_matrix['FN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EAQsqqeRqQBE"
   },
   "outputs": [],
   "source": [
    "#Accuracy function\n",
    "def accuracy(confusion_matrix):\n",
    "    return (confusion_matrix['TP'] + confusion_matrix['TN']) / sum(confusion_matrix.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H1WG2r8PqQBF"
   },
   "outputs": [],
   "source": [
    "#f1 score\n",
    "def f1(confusion_matrix):\n",
    "    precision_score = precision(confusion_matrix)\n",
    "    recall_score = recall(confusion_matrix)\n",
    "    numerator = precision_score * recall_score\n",
    "    denominator = precision_score + recall_score\n",
    "    return 2 * (numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hMyoP-zGqQBG",
    "outputId": "e08479b9-b237-4d6e-8c10-96ff9be4ab60"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "\n",
    "preds = [y_hat_train]\n",
    "\n",
    "for ind, i in enumerate(preds):\n",
    "    print('-'*40)\n",
    "    print('Model Metrics:'.format(ind + 1))\n",
    "    print('Precision: {}'.format(precision_score(y_train, i)))\n",
    "    print('Recall: {}'.format(recall_score(y_train, i)))\n",
    "    print('Accuracy: {}'.format(accuracy_score(y_train, i)))\n",
    "    print('F1-Score: {}'.format(f1_score(y_train, i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxIYhMSGqQBH",
    "outputId": "98254056-ada4-4891-91f2-0510d809c935"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "for ind, i in enumerate(preds):\n",
    "    print('-'*40)\n",
    "    print(\"Model Classification Report:\".format(ind + 1))\n",
    "    print(classification_report(y_train, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J4IXrteDMtsd"
   },
   "source": [
    "## Cross Validation\n",
    "Repeat a train-test-split creation 20 times, using a test_size of 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PEsy9nkWqQBJ",
    "outputId": "d21b6bb4-182a-4b07-d739-8ba0907ddf7b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num = 20\n",
    "train_err = []\n",
    "test_err = []\n",
    "for i in range(num):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)\n",
    "    logreg2.fit(X_train, y_train)\n",
    "    y_hat_train = logreg2.predict(X_train)\n",
    "    y_hat_test = logreg2.predict(X_test)\n",
    "    train_err.append(mean_squared_error(y_train, y_hat_train))\n",
    "    test_err.append(mean_squared_error(y_test, y_hat_test))\n",
    "plt.scatter(list(range(num)), train_err, label='Training Error')\n",
    "plt.scatter(list(range(num)), test_err, label='Testing Error')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J_P8W2mSqQBK",
    "outputId": "0c9b8a71-16da-4e82-ebb9-92ddd58ad83c"
   },
   "outputs": [],
   "source": [
    "#K-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_5_results = np.mean(cross_val_score(logreg2, X, y, cv=5, scoring=\"accuracy\"))\n",
    "cv_10_results = np.mean(cross_val_score(logreg2, X, y, cv=10, scoring=\"accuracy\"))\n",
    "cv_20_results = np.mean(cross_val_score(logreg2, X, y, cv=20, scoring=\"accuracy\"))\n",
    "\n",
    "print(cv_5_results)\n",
    "print(cv_10_results)\n",
    "print(cv_20_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8FTNEySL-r1"
   },
   "source": [
    "## Create a Sequential Neural Network\n",
    "- ReLU activation function\n",
    "- Sigmoid function on the output layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oWR8x3d1L-r3",
    "outputId": "8604551e-a247-4b56-985d-14e88656abc8"
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# split into input (X) and output (y) variables\n",
    "X = pd.get_dummies(df_mvp[x_feats], drop_first=False)\n",
    "y = df_mvp.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0OR6gL5nCzS"
   },
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=18, activation='relu'))\n",
    "model.add(Dense(19, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U3RBwALtL-r6"
   },
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KHBHfbT2L-r7"
   },
   "outputs": [],
   "source": [
    "# Set callback functions to early stop training and save the best model so far\n",
    "checkpoint = [ModelCheckpoint(filepath='models.hdf5', save_best_only=True, monitor='val_loss')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gvBhhejgL-r9",
    "outputId": "ce0eadca-c9e3-4e93-a575-366a329366df"
   },
   "outputs": [],
   "source": [
    "# fit the keras model on the dataset\n",
    "model.fit(X, y, epochs=10, callbacks=checkpoint, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kvf2AxWWL-sA",
    "outputId": "fc87557a-8182-467f-d1d5-5d341ccd8674"
   },
   "outputs": [],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VsTAEuRbqQBT"
   },
   "source": [
    "## Create a Sequential Neural Network with the scaled data\n",
    "- ReLU activation function\n",
    "- Sigmoid function on the output layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ojIfMtATqQBU"
   },
   "outputs": [],
   "source": [
    "# split into input (X) and output (y) variables\n",
    "X = pd.get_dummies(X_train, drop_first=False) #X_train = upsampled.drop('sentiment', axis=1)\n",
    "y = y_train #y_train = upsampled.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3n7DM1OWqQBV"
   },
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(12, input_dim=18, activation='relu'))\n",
    "model2.add(Dense(8, activation='relu'))\n",
    "model2.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "scXb6rOcqQBW"
   },
   "outputs": [],
   "source": [
    "# compile the keras model\n",
    "model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9pyOTHAfqQBX"
   },
   "outputs": [],
   "source": [
    "# Set callback functions to early stop training and save the best model so far\n",
    "checkpoint = [ModelCheckpoint(filepath='models.hdf5', save_best_only=True, monitor='val_loss')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FdWpHr0qQBY",
    "outputId": "964ca7c1-fd50-4696-9053-6c03d75c7203"
   },
   "outputs": [],
   "source": [
    "# fit the keras model on the dataset\n",
    "model2.fit(X, y, epochs=10, callbacks=checkpoint, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Na0fLdDgqQBZ",
    "outputId": "e1b30fbd-76f1-476f-da97-a7ee6b43dfd6"
   },
   "outputs": [],
   "source": [
    "# evaluate the keras model\n",
    "_, accuracy = model2.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Uytuuf9unCyG",
    "GDvHzkARnCyU"
   ],
   "name": "student.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
